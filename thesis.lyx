#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_amsmath 1
\use_esint 1
\use_mhchem 1
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 1
\backgroundcolor #ffffff
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 4
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title

\family typewriter
\size huge
A Schedulability Compatible Multiprocessor Resource Sharing Protocol
\end_layout

\begin_layout Standard
\align center

\size largest
Msc Computing Dissertation
\end_layout

\begin_layout Standard
\align center

\size largest
Y0017846
\end_layout

\begin_layout Standard
\align center

\shape smallcaps
\size largest
University of York
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vspace*{
\backslash
fill}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Abstract
Multiprocessor real-time resource control algorithms are currently an active
 research topic as more and more real-time systems become multicore.
\end_layout

\begin_layout Abstract
This project intends to contribute to the field of multiprocessor resource
 sharing protocols in real-time systems.
 Multiprocessor architectures have become mainstream, used in small embedded
 devices as well as enterprise servers.
 Multiple processing units architectures offer increasing computational
 capacity performance that need to be efficiently employed.
 While we can expect massively multi-core processors chips to be available
 soon, research in the real-time systems has been mainly designed for single
 processors.
 The widespread use of multicore architectures is challenging the real-time
 systems area for a protocol that could make a consensus and presenting
 features that are at least as good as the single processor protocols.
 The purpose of a lock-based multiprocessor resource sharing protocol implementa
tion in an operating system as popular as Linux is a step forward to catch
 up on processor manufacturers.
\end_layout

\begin_layout Abstract
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Standard

\size larger
Ideas
\end_layout

\begin_layout Standard
Difference between scheduling and resource sharing
\end_layout

\begin_layout Standard
Chart illustrating the protocol (state machine diagram)
\end_layout

\begin_layout Standard
Implement prototype in C as a working stand alone state machine (without
 kernel complexities)
\end_layout

\begin_layout Standard
Importance of metrics
\end_layout

\begin_layout Standard
Implement protocol with kernel
\end_layout

\begin_layout Standard

\series bold
Investigate : How does Linux do SMP real-time scheduling ?
\end_layout

\begin_layout Standard

\series bold
Investigate : How to allow threads to have a priority per processor ?
\end_layout

\begin_layout Standard
How do we assess/certify the priority of threads ?
\end_layout

\begin_layout Standard
How can the Linux Kernel be modified to allow a priority per processor ?
 
\end_layout

\begin_layout Enumerate
Modify task_struct in sched.h and add a priority per processor variable
\end_layout

\begin_layout Enumerate
Modify migrate_thread to set the new priority on that processor
\end_layout

\begin_layout Standard
What is the estimated time ?
\end_layout

\begin_layout Standard
Is there an overhead associated to a priority per processor ?
\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Section
Overview
\end_layout

\begin_layout Standard
This section will briefly describe the reasons for undertaking this project.
 It will introduce the technical requirements involved, as well as present
 the development workflow and finally the ethics used to complete it.
\end_layout

\begin_layout Subsection
Motivation
\end_layout

\begin_layout Standard
The Real-Time System Group at York have recently proposed a new resource
 sharing algorithm
\begin_inset CommandInset citation
LatexCommand cite
key "burns2013schedulability"

\end_inset

 based on a well known single processor resource sharing protocol.
 This report provides an implementation in a Linux Real-Time kernel.
 
\end_layout

\begin_layout Subsection
Project Goals
\end_layout

\begin_layout Subsection
Deliverables
\end_layout

\begin_layout Subsection
Ethics in the project
\end_layout

\begin_layout Subsection
Report structure
\end_layout

\begin_layout Section
Background
\end_layout

\begin_layout Subsection
Real-time systems
\end_layout

\begin_layout Standard
In the real-time paradigm besides of the usually expected functional correctness
 of a system, the timing e.g.
 the time needed to process an input must comply with a deadline.
 Young
\begin_inset CommandInset citation
LatexCommand cite
key "young1982real"

\end_inset

 gives the following definition : 
\end_layout

\begin_layout Quote

\shape italic
Any information processing activity or system which has to respond to externally
 generated input stimuli within a finite and specified period.
\end_layout

\begin_layout Standard
A real-time system is ordinarily composed of concurrent tasks sharing common
 resources.
 Tasks execute a sequence of operations in parallel, they have a deadline
 representing the maximum acceptable execution time.
 Tasks can be classified as periodic meaning they are triggered at regular
 intervals or aperiodic meaning they can be triggered at any time.
 A subset of aperiodic tasks are sporadic tasks, these can be triggered
 at any time with the condition that they respect a minimum time between
 each release.
\end_layout

\begin_layout Standard
Concurrent programming has been studied and developed a long time before
 the apparition of multiprocessors architectures.
 It might seem odd to have concurrent execution of tasks on single processor
 systems and indeed operating systems 
\shape italic
give the impression 
\shape default
of concurrency by allocating short execution time to each task according
 to a policy implemented in the task scheduler.
\end_layout

\begin_layout Standard
We make the difference between 
\shape italic
hard, soft 
\shape default
and
\shape italic
 firm
\shape default
 real-time systems.
 Hard real-time systems put a strict constraint on respecting the deadline,
 they are usually used in industries in which response time is critical
 and where a failure to execute within the deadline equals to a system failure.
 On the other hand, soft real-time systems consider the deadline as a recommenda
tion therefore missing a deadline is not a serious error however it does
 decrease the value of the expected output.
 In firm real-time systems, missing a deadline is not a system failure although
 the output of a task is discarded by the system.
\end_layout

\begin_layout Subsection
Real-time multiprocessor scheduling
\end_layout

\begin_layout Standard
Operating systems implement schedulers to efficiently allocate processor
 resource time to tasks.
 Schedulers are inherent to multitasking.
\end_layout

\begin_layout Standard
Real-time multiprocessor scheduling protocols are divided among three classes
 : 
\shape italic
partitioned scheduling, semi-partitioned scheduling 
\shape default
and
\shape italic
 global scheduling
\end_layout

\begin_layout Standard
Each above class can be implemented with either 
\shape italic
fixed-priority (FP) 
\shape default
or
\shape italic
 earliest-deadline-first
\shape default
 (EDF) policies.
\end_layout

\begin_layout Subsubsection
Scheduling Policies
\end_layout

\begin_layout Subsubsection
Scheduling protocols
\end_layout

\begin_layout Paragraph
Global scheduling protocols
\end_layout

\begin_layout Standard
In global scheduling, a single queue of tasks is dispatched among the processors.
 Global scheduling protocols traditionally have an EDF policy.
\end_layout

\begin_layout Paragraph
Partitioned scheduling protocols
\end_layout

\begin_layout Standard
In partitioned scheduling each task is statically assigned a processor e.g.
 migrations between processors are not allowed.
 Each processor is scheduled independently.
 In other words partitioning reduces the multiprocessor scheduling problem
 to a set of uniprocessor
\begin_inset CommandInset citation
LatexCommand cite
key "carpenter2004categorization"

\end_inset

.
 This form of scheduling is the most used because it reuses well-known concepts
 of uniprocessor scheduling.
\end_layout

\begin_layout Paragraph
Semi-partitioned protocols
\end_layout

\begin_layout Standard
Semi-partitioned protocols are a compromise between global and partitioned
 protocols.
 Processors are grouped into subsets.
 A task is statically assigned to a set of processors.
 Each subset is then scheduled globally.
 
\end_layout

\begin_layout Subsection
Real-time resource sharing on multiprocessors
\end_layout

\begin_layout Standard

\series bold
The major problems are : 
\end_layout

\begin_layout Enumerate

\series bold
Deadlocks (nested resources)
\end_layout

\begin_layout Enumerate

\series bold
Unbounded Priority Inversion -> Priority inheritance meant to solve this
\end_layout

\begin_layout Enumerate

\series bold
Local Or Global Resources
\end_layout

\begin_layout Enumerate

\series bold
Suspend based or Spin based
\end_layout

\begin_layout Enumerate

\series bold
Schedulability Analysis (Response Time Analysis)
\end_layout

\begin_layout Enumerate

\series bold
Resource starvation
\end_layout

\begin_layout Standard

\series bold
The performance parameter are:
\end_layout

\begin_layout Enumerate

\series bold
Contention of High priority threads
\end_layout

\begin_layout Standard
Mutual exclusion to a critical section may be implemented on a uniprocessor
 (UP) system by simply preventing the thread that accesses the section from
 being preempted.
 On a symmetric multiprocessor (SMP) system, disabling pre- emption is not
 enough.
 A thread on another CPU might access the critical section.
 [Internal RT paper]
\end_layout

\begin_layout Standard
____________________
\end_layout

\begin_layout Standard
Spin_locks are relatively fast.
 The idea behind a spin_lock is to protect critical sections that are very
 short.
 A spin_lock is considered fast compared to suspend-based locks because
 it avoids the overhead of a re-schedule.
 [Internal RT papers]
\end_layout

\begin_layout Standard
____________________
\end_layout

\begin_layout Standard
If the time to run the code in a critical section is shorter than the time
 of a context switch, it is reasonable to use a spin_lock, and on contention,
 spin in a busy loop, while waiting for a thread on another CPU to release
 the spin_lock.
 [Internals RT]
\end_layout

\begin_layout Subsubsection
Non Preemptive Protocol
\end_layout

\begin_layout Standard
The Non Preemptive Protocol is a simple approach to resource sharing.
 It can be described as follows : when a task enters a mutually exclusive
 area it can't be preempted.
 However this protocol allows low priority tasks to block higher priority
 tasks that are not even requiring access to shared resources.
 It is a form of priority inversion.
\end_layout

\begin_layout Subsubsection
Highest Locker Priority
\end_layout

\begin_layout Subsubsection
Priority Inheritance Protocol
\end_layout

\begin_layout Subsubsection
Stack Resource Policy
\end_layout

\begin_layout Subsubsection
The Priority Ceiling Protocol on Uniprocessors
\end_layout

\begin_layout Standard
The priority ceiling protocol a well-known uniprocessor protocol is at the
 root of many multiprocessor resource sharing protocols on partitioned systems
 because one common strategy in scheduling it to treat each processor independen
tly.
 Each resource is associated to a priority which is the maximum priority
 of all tasks using that resource (ceiling).
 When trying to acquire that resource, a tasks sees its priority raised
 to the resource's ceiling.
 This protocol is designed to avoid priority inversion 
\series bold
[DEFINE IT] 
\series default
an indesirable scenario in real-time scheduling.
 PCP makes use of a technique called priority inheritance which consists
 of dynamically changing a tasks priority to avoid preemption and improve
 schedulability.
\end_layout

\begin_layout Subsubsection
The Multiprocessor Priority Ceiling Protocol (MPCP)
\end_layout

\begin_layout Paragraph
Description
\end_layout

\begin_layout Standard
Rajkumar designed Multiprocessor Priority Ceiling Protocol (MPCP ) 
\series bold
[REF]
\series default
 that extends PCP (Priority Ceiling Protocol).
 Resources are regarded as local or global e.g.
 shared between tasks on different processors.
 Local resources locking is managed using PCP.
 However when acquiring a lock to a global resource, the holding task gets
 its priority raised to a value higher than all running tasks priorities
 in the system.
 If the resource is already held the requesting task is queued to a waiting
 list and its priority raised to the resource ceiling.
 As noted by 
\begin_inset CommandInset citation
LatexCommand cite
key "davis2011survey"

\end_inset

 while MPCP allows for lower tasks to execute while a global lock is held
 by a task on another processor, this can lead to a further priority inversion
 with a lower task executing taking first a local lock and then a global
 one.
 Even if the resource the higher task is waiting on is released it won't
 be able to execute.
\end_layout

\begin_layout Paragraph
Constraints
\end_layout

\begin_layout Standard
To prevent unbounded priority inversion, local to global and global to global
 nested locks are not allowed.
\end_layout

\begin_layout Paragraph
Performance
\end_layout

\begin_layout Paragraph
Limitations
\end_layout

\begin_layout Subsubsection
The Multiprocessor Stack Resource Policy (MSRP)
\end_layout

\begin_layout Paragraph
Description
\end_layout

\begin_layout Standard
The Multiprocessor Stack Resource Policy (MRSP) is an extension proposed
 by [REF] of the uniprocessor Stack Resource Policy from [REF] (SRP).
 SRP is an EDF protocol.
 The deadline of each task represents a priority level.
 The earlier the deadline the higher the priority.
 Each resource is assigned a priority ceiling corresponding to the priority
 level of the higher task using that resource.
 A new M parameter is also introduced, M corresponds to the maximum of all
 the resources ceiling being used at instant T.
 Any task wanting to execute must have a priority higher than M.
\end_layout

\begin_layout Standard
SRP guarantees no blocking when a task is allowed to execute thus enabling
 stack sharing (each task execution is serialized - no interleaving).
\end_layout

\begin_layout Standard
Under MRSP as in MPCP resources are divided into local and global groups.
 Global resources have one ceiling per processor.
 A task on a processor is allowed to execute only if it has the processor
 ceiling priority which preserve the property of non-preemptability once
 a task starts executing.
\end_layout

\begin_layout Standard
Furthermore when a task is blocked on a global resource, it spins non-preemptive
ly to preserve the stack sharing property.
\end_layout

\begin_layout Standard
Tasks accessing nested local and global resources need to be allocated the
 same processor[CHECK].
 
\end_layout

\begin_layout Paragraph
Constraints
\end_layout

\begin_layout Paragraph
Performance
\end_layout

\begin_layout Paragraph
Limitations
\end_layout

\begin_layout Subsubsection
The Flexible Multiprocessor Locking Protocol (FMLP) 
\end_layout

\begin_layout Standard
FMLP requires the user to divide resources between long and short access
 times.
 Access is differentiated in function of the type of the resource : short
 resources benefit from busy-waiting (reduces context-switching), long resources
 are handled through suspend-waiting in a FIFO manner.
 A task holding a short resource is not allowed to require access to a long
 resource to avoid deadlock.
 
\end_layout

\begin_layout Paragraph
Description
\end_layout

\begin_layout Paragraph
Constraints
\end_layout

\begin_layout Paragraph
Performance
\end_layout

\begin_layout Standard
FMLP has better performance than MSRP.
 This advantage is at least partly due to the fact that FMLP removes the
 restriction on task allocation required by MSRP 
\begin_inset CommandInset citation
LatexCommand cite
key "davis2011survey"

\end_inset

.
 
\end_layout

\begin_layout Paragraph
Limitations
\end_layout

\begin_layout Subsubsection
Parallel PCP (P-PCP) 
\end_layout

\begin_layout Subsubsection
O(m) Locking Protocol (OMLP) 
\end_layout

\begin_layout Standard
OMLP makes use of a two-level priority queue scheme to allow access to a
 global resource.
 
\end_layout

\begin_layout Standard
Under partitioned scheduling, tasks requiring access to a global resource
 are first put on local priority queue and then in a global prioritized
 queue.
 The highest priority task on the local queue is selected to be put on the
 global queue and its priority is raised to the local ceiling (maximum priority
 being used on the processor) to make it locally non-preemptible, however
 the task might still be suspended if there is high contention on the global
 queue.
\end_layout

\begin_layout Standard
Under global scheduling, tasks requiring access to a 
\end_layout

\begin_layout Subsubsection
Multiprocessor Synchronization Protocol for Real-Time Open Systems (MSOS)
 
\end_layout

\begin_layout Subsubsection
M-BWI 
\end_layout

\begin_layout Standard
Many other protocols exist
\end_layout

\begin_layout Subsection
The Multiprocessor Resource Sharing Protocol
\end_layout

\begin_layout Subsubsection
Description
\end_layout

\begin_layout Standard
Here we present informally the protocol as it is described in details in
 
\begin_inset CommandInset citation
LatexCommand cite
key "burns2013schedulability"

\end_inset


\end_layout

\begin_layout Standard
We assume a fully partitioned system.
 That is, each thread can only execute on one processor.
 
\end_layout

\begin_layout Enumerate
All mutex are assigned a set of ceiling priorities, one per processor (for
 those processors that have threads that use the mutex); for processor Pk
 it is the maximum priority of all threads allocated to Pk that use the
 mutex.
 
\end_layout

\begin_layout Enumerate
A lock request on any mutex results in the priority of the thread being
 immediately raised (ICPP) to the local ceiling for the mutex.
 
\end_layout

\begin_layout Enumerate
Accesses to a mutex are dealt with in a FIFO order.
 
\end_layout

\begin_layout Enumerate
While waiting to gain access to the mutex, and while actually holding the
 mutex, the thread continues to be active and executes (possible spinning)
 with priority equal to the local ceiling of the mutex.
 
\end_layout

\begin_layout Enumerate
Any thread waiting to gain access to a mutex must be capable of undertaking
 the associated computation on behalf of any other waiting thread (SPEPP).
 
\end_layout

\begin_layout Enumerate
This cooperating thread must undertake the outstanding requests in the original
 FIFO order.
 
\end_layout

\begin_layout Subsubsection
A migration approach
\end_layout

\begin_layout Standard
While the protocol developed is intended for partitioned systems, thread
 migration between processors is common in SMP operating systems.
\end_layout

\begin_layout Standard
Migration-based classification 
\begin_inset CommandInset citation
LatexCommand cite
key "carpenter2004categorization"

\end_inset

.
 Interprocessor migration has traditionally been forbidden in real-time
 systems for the following reasons: 
\end_layout

\begin_layout Standard
• In many systems, the cost associated with each migration — i.e.
 , the cost of transferring a job’s context from one processor to another
 — can be prohibitive.
 
\end_layout

\begin_layout Standard
• Until recently, traditional real-time scheduling theory lacked the techniques,
 tools, and results to permit a detailed analysis of systems that allow
 migration.
 Hence, partitioning has been the preferred approach due largely to the
 non-existence of viable alternative approaches.
 Recent developments in computer architecture, including single-chip multiproces
sors and very fast interconnection networks over small areas, have resulted
 in the first of these concerns becoming less of an issue.
 Thus, system designers need no longer rule out interprocessor migration
 solely due to implementation considerations, especially in tightly-coupled
 systems.
 (However, it may still be desirable to strict overhead in order to reduce
 runtime overhead.) In addition, results of recent experiments demonstrate
 that scheduling algorithms that allow migration are competitive in terms
 of schedulability with those that do not migrate, even after incorporating
 migration overheads [26].
 This is due to the fact that systems exist that can be successfully scheduled
 only if interprocessor 5 migration is allowed (refer to Lemmas 3 and 4
 in Section 3)
\end_layout

\begin_layout Standard
Migration addresses points 5 and 6 of the protocol : A thread that is spinning
 for a lock already held on another processor must be able to give way to
 the preempted holder locally.
\end_layout

\begin_layout Subsubsection
Schedulability Analysis
\end_layout

\begin_layout Subsubsection
Runtime Overhead in SMP computers
\end_layout

\begin_layout Subsubsection
Limitations
\end_layout

\begin_layout Section
Characteristics of SMP machines
\end_layout

\begin_layout Subsection
Processor affinity
\end_layout

\begin_layout Subsection
Processor Caches
\end_layout

\begin_layout Subsection
Cost of migration 
\end_layout

\begin_layout Standard
The cost of two migrations must be less than the interference of a higher
 priority thread.
 Also a migrating thread is likely to suffer from an execution time penalty
 as its local cache cannot be utilised.
 However, a preempted thread is also likely to have its data in cache overwritte
n by the time it executes again.
 
\end_layout

\begin_layout Section
Overview of Real-time in Linux Vs RTOSes
\end_layout

\begin_layout Subsection
RT-patch
\end_layout

\begin_layout Subsubsection
Kernel Preemption
\end_layout

\begin_layout Itemize
Linux, prior to the 2.5 Linux Kernel, was a non-preemptive kernel.
 That means that whenever a thread was running in 
\series bold
kernel context
\series default
 (for instance a user application making a system call) that thread would
 not be preempted unless it volunteered to schedule (calls yield() function)
 -> basic Non Preemptive Protocol.
 The 2.6 version of the Linux Kernel introduces preemption and protects critical
 section through the use of spin-locks e.g.
 busy-waiting locks 
\begin_inset CommandInset citation
LatexCommand cite
key "rostedt2007internals"

\end_inset

.
 This was a major improvement however it still allowed lower threads blocking
 higher threads requesting access to the same shared resource or not.
 It makes sense for a spinlock to be fully non-preemptible for the following
 reasons: 
\end_layout

\begin_layout Itemize
Busy-waiting blocks a whole processor, we want to access and leave the critical
 section rapidly.
 
\end_layout

\begin_layout Itemize
Other tasks might be spinning on different processors for the same lock
\end_layout

\begin_layout Itemize
Interrupt kernel threads [
\series bold
Define
\series default
] are given priority over all other tasks, they can spin on the lock held
 by the preempted task and thus create a deadlock.
\end_layout

\begin_layout Standard
However spinlocks can create large non-deterministic latencies and that
 is conflicting with the requirements of an RTOS.
\end_layout

\begin_layout Standard
To address that issue the RT patch converts most spinlocks into a mutex
 
\begin_inset CommandInset citation
LatexCommand cite
key "rostedt2007internals"

\end_inset

, this has the effect to enable preemption in the critical sections as a
 task trying to lock an already held mutex will be suspended (deadlock avoided).
\end_layout

\begin_layout Subsubsection
Priority Inheritance Implementation
\end_layout

\begin_layout Standard
Priority inversion, lower tasks blocking higher ones is inherent to scheduling
 and can not be avoided, however unbounded priority inversion must be prevented.
 The RT patch chooses priority inheritance to address this issue.
\end_layout

\begin_layout Standard
The implementation of a PI mutex introduces a new concept, the priority
 inheritance chain described in 
\begin_inset CommandInset citation
LatexCommand cite
key "rostedt_rt_mutex"

\end_inset

.
\end_layout

\begin_layout Standard
The PI chain is an ordered series of locks and processes that cause tasks
 to inherit priorities from a higher process that is blocked on one of its
 locks.
 Different chains may be merged as several tasks can wait on a lock, but
 a chain would never diverge, since a task can't be blocked on more than
 one lock at a time.
 
\end_layout

\begin_layout Subsubsection
High Resolution Timers
\end_layout

\begin_layout Subsection
Comparison with other RTOSes
\end_layout

\begin_layout Section
Implementation in Linux Kernel
\end_layout

\begin_layout Subsection
Requirements of MrsP
\end_layout

\begin_layout Standard
Be able to assign one priority per processor to mutexes
\end_layout

\begin_layout Standard
Make waiters spin and be able to get preempted only by holder
\end_layout

\begin_layout Standard
Make waiters add their affinities to holder
\end_layout

\begin_layout Subsection
The Linux real-time scheduling algorithm
\end_layout

\begin_layout Subsubsection
Key Data Structures
\end_layout

\begin_layout Paragraph
task_struct
\end_layout

\begin_layout Standard
This data structure represents a task in the system.
 It contains useful information for the scheduler such as the real-time
 priority of a task, its current state (running, sleeping, etc..) and the
 policy under which it is being scheduled.
 
\end_layout

\begin_layout Paragraph
runqueue
\end_layout

\begin_layout Standard
There is two runqueue per processor, one of which is listing the active
 tasks and the other the expired task.
 A runqueue is a linked list composed of 140 nodes corresponding to each
 priority level.
 Each node is itself a linked list referencing the tasks of the same priority.
\end_layout

\begin_layout Paragraph
futex
\end_layout

\begin_layout Standard
A futex, 
\begin_inset Quotes eld
\end_inset

Fast userspace mutex
\begin_inset Quotes erd
\end_inset

, is a locking primitive that is used to build more complex locking structures.
 It is composed of a 32 bits integer and a waitqueue referencing the tasks
 waiting to acquire the lock.
 It is used in mutexes when there is contention over a lock (a task is waiting
 for a lock already hold).
\end_layout

\begin_layout Paragraph
rt_mutex
\end_layout

\begin_layout Standard
Also called Priority inheritance futex, like with futexes, the waiting task
 is added to a waitqueue.
 If its priority is higher than the holder's, it rises the holder's priority
 to its own priority.
 The priority inheritance is dynamic in the sense that, if the holder is
 itself waiting on a second futex, its temporarily enhanced priority will
 diffuse to the holder of the second futex.
 As soon as a task unlocks a futex its enhanced priority is set back to
 its initial one.
\end_layout

\begin_layout Subsubsection
Real-time scheduler
\end_layout

\begin_layout Standard
root domains
\end_layout

\begin_layout Standard
Pull and Push algorithms
\end_layout

\begin_layout Subsubsection
Priority Management in kernel
\end_layout

\begin_layout Subsection
Implementation of MrsP 
\end_layout

\begin_layout Standard
We have added a variable in the task_struct definition that can hold one
 priority per processor
\end_layout

\begin_layout Standard
We have added a bitmask in the task_struct definition that holds the inherited
 processor affinities.
 Those are added to the task holding the lock and removed when it releases
 the lock.
\end_layout

\begin_layout Standard
We have added a boolean variable to make a task scheduled under our algorithm.
 TODO to be modified for a new scheduling policy (SCHED_MRSP).
\end_layout

\begin_layout Standard
A call to sys_futex with SCHED_MRSP makes the thread spin at local ceiling
 for the rt-mutex.
\end_layout

\begin_layout Standard
The task is checked when being migrated between two cpus, if a task is spinning
 on that cpu, it raises its own priority to task_on_other_cpu +1 so that
 it can preempt it.
\end_layout

\begin_layout Standard
We take advantage of the previously implemented PI-futexes.
\end_layout

\begin_layout Subsubsection
MRSP API
\end_layout

\begin_layout Standard
A system call sys_set_smp_prio allows to set one priority per task.
\end_layout

\begin_layout Standard
Task spinning giving up its share -> cooperative scheduling ?
\end_layout

\begin_layout Subsection
Semi-partitioned systems considerations
\end_layout

\begin_layout Subsection
Globally partitioned systems considerations
\end_layout

\begin_layout Subsection
Limitations
\end_layout

\begin_layout Section
Results and evaluation
\end_layout

\begin_layout Subsection
Tools
\end_layout

\begin_layout Subsubsection
QEMU
\end_layout

\begin_layout Subsubsection
Kernelshark and trace-cmd
\end_layout

\begin_layout Subsubsection
ftrace
\end_layout

\begin_layout Subsection
Hardware
\end_layout

\begin_layout Subsection
Test Cases
\end_layout

\begin_layout Section
Conclusion
\end_layout

\begin_layout Subsection
Strengths
\end_layout

\begin_layout Subsection
Weaknesses
\end_layout

\begin_layout Subsection
Limitations
\end_layout

\begin_layout Subsection
Implications
\end_layout

\begin_layout Subsection
Recommendation for further research
\end_layout

\begin_layout Standard
Given the plethora of available resource sharing protocols.
\end_layout

\begin_layout Standard
Each resource sharing protocol seems to suit a particular type of programming
 (slow or quick resources, intensive or sparse sharing, number of tasks,
 etc..).
 An approach that might be considered is to build a framework that automatically
 selects the best resource sharing algorithm for a given program.
 Why not even think about dynamically changing a policy during runtime,
 going to the realm of strategy (schedulability) and tactics (different
 protocols).
\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "cite"
options "plain"

\end_inset


\end_layout

\end_body
\end_document
