#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass article
\begin_preamble
\usepackage{pgfgantt}
\end_preamble
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref true
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder false
\pdf_colorlinks false
\pdf_backref false
\pdf_pdfusetitle true
\papersize default
\use_geometry false
\use_amsmath 1
\use_esint 1
\use_mhchem 1
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 1
\backgroundcolor #ffffff
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 4
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title

\family typewriter
\size huge
A Schedulability Compatible Multiprocessor Resource Sharing Protocol
\end_layout

\begin_layout Standard
\align center

\size largest
Msc Software Engineering Dissertation
\end_layout

\begin_layout Standard
\align center

\size largest
Y0017846
\end_layout

\begin_layout Standard
\align center

\shape smallcaps
\size largest
University of York
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vspace*{
\backslash
fill}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Standard
\begin_inset FloatList figure

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Abstract
Multiprocessor real-time resource control algorithms are currently an active
 research topic as more and more real-time systems become multicore.
\end_layout

\begin_layout Abstract
This project intends to contribute to the field of multiprocessor resource
 sharing protocols in real-time systems.
 Multiprocessor architectures have become mainstream, used in small embedded
 devices as well as enterprise servers.
 Multiple processing units architectures offer increasing computational
 capacity performance that need to be efficiently employed.
 While we can expect massively multi-core processors chips to be available
 soon, research in the real-time systems has been mainly designed for single
 processors.
 The widespread use of multicore architectures is challenging the real-time
 systems area for a protocol that could make a consensus and presenting
 features that are at least as good as the single processor protocols.
 The purpose of a lock-based multiprocessor resource sharing protocol implementa
tion in an operating system as popular as Linux is a step forward to catch
 up on processor manufacturers.
\end_layout

\begin_layout Abstract
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Standard

\size larger
Ideas
\end_layout

\begin_layout Standard
Difference between scheduling and resource sharing
\end_layout

\begin_layout Standard
Chart illustrating the protocol (state machine diagram)
\end_layout

\begin_layout Standard
Implement prototype in C as a working stand alone state machine (without
 kernel complexities)
\end_layout

\begin_layout Standard
Importance of metrics
\end_layout

\begin_layout Standard
Implement protocol with kernel
\end_layout

\begin_layout Standard

\series bold
Investigate : How does Linux do SMP real-time scheduling ?
\end_layout

\begin_layout Standard

\series bold
Investigate : How to allow threads to have a priority per processor ?
\end_layout

\begin_layout Standard
How do we assess/certify the priority of threads ?
\end_layout

\begin_layout Standard
How can the Linux Kernel be modified to allow a priority per processor ?
 
\end_layout

\begin_layout Enumerate
Modify task_struct in sched.h and add a priority per processor variable
\end_layout

\begin_layout Enumerate
Modify migrate_thread to set the new priority on that processor
\end_layout

\begin_layout Standard
What is the estimated time ?
\end_layout

\begin_layout Standard
Is there an overhead associated to a priority per processor ?
\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
This section will briefly describe the reasons for undertaking this project.
 It will introduce the technical requirements involved, as well as present
 the development workflow and finally the ethics used to complete it.
\end_layout

\begin_layout Subsection
Motivation
\end_layout

\begin_layout Standard
The Real-Time System Group at York have recently proposed a new multiprocessor
 resource sharing algorithm
\begin_inset CommandInset citation
LatexCommand cite
key "burns2013schedulability"

\end_inset

 based on a well known single processor resource sharing protocol.
 This report provides an implementation in a Linux Real-Time kernel.
 
\end_layout

\begin_layout Subsection
Project Goals
\end_layout

\begin_layout Subsection
Deliverables
\end_layout

\begin_layout Subsection
Ethics in the project
\end_layout

\begin_layout Subsection
Report structure
\end_layout

\begin_layout Section
Background and Literature Review
\end_layout

\begin_layout Subsection
Real-time systems
\end_layout

\begin_layout Standard
In the real-time paradigm besides of the usually expected functional correctness
 of a system, the timing e.g.
 the time needed to process an input must comply with a deadline.
 Wellings and Burns
\begin_inset CommandInset citation
LatexCommand cite
key "burns2001real"

\end_inset

 cite Young
\begin_inset CommandInset citation
LatexCommand cite
key "young1982real"

\end_inset

 for the definition of a real-time system: 
\end_layout

\begin_layout Quote

\shape italic
Any information processing activity or system which has to respond to externally
 generated input stimuli within a finite and specified period.
\end_layout

\begin_layout Standard
A real-time system is ordinarily composed of concurrent tasks sharing common
 resources.
 Tasks execute a sequence of operations in parallel, they have a deadline
 representing the maximum acceptable response time.
 Tasks can be classified as periodic meaning they are triggered at regular
 intervals or aperiodic meaning they can be triggered at any time.
 A subset of aperiodic tasks are sporadic tasks, these can be triggered
 at any time with the condition that they respect a minimum time between
 each release.
\end_layout

\begin_layout Standard
Concurrent programming has been studied and developed a long time before
 the apparition of multiprocessors architectures.
 It might seem odd to have concurrent execution of tasks on single processor
 systems and indeed operating systems 
\shape italic
give the impression 
\shape default
of concurrency by allocating short execution time to each task according
 to a policy implemented in the task scheduler.
 In real time systems, the scheduling is performed using task priorities.
\end_layout

\begin_layout Standard
We make the difference between 
\shape italic
hard, soft 
\shape default
and
\shape italic
 firm
\shape default
 real-time systems.
 Hard real-time systems put a strict constraint on respecting the deadline,
 they are usually used in industries in which response time is critical
 and where a failure to execute within the deadline equals to a system failure.
 On the other hand, soft real-time systems consider the deadline as a recommenda
tion therefore missing a deadline is not a serious error however it does
 decrease the value of the expected output.
 In firm real-time systems, missing a deadline is not a system failure although
 the output of a task is discarded by the system.
\end_layout

\begin_layout Subsection
Real-time multiprocessor scheduling
\end_layout

\begin_layout Standard
Operating systems implement schedulers to efficiently allocate processor
 resource time to tasks.
 Schedulers are inherent to multitasking.
\end_layout

\begin_layout Standard
Real-time multiprocessor scheduling protocols are divided among three classes
 : 
\shape italic
partitioned scheduling, semi-partitioned scheduling 
\shape default
and
\shape italic
 global scheduling
\end_layout

\begin_layout Standard
Each above class can be implemented with either 
\shape italic
fixed-priority (FP) 
\shape default
or
\shape italic
 earliest-deadline-first
\shape default
 (EDF) policies.
\end_layout

\begin_layout Subparagraph
Real time systems desirable properties /requirements
\end_layout

\begin_layout Subsubsection
Scheduling Policies
\end_layout

\begin_layout Subsubsection
Scheduling protocols
\end_layout

\begin_layout Paragraph
Global scheduling protocols
\end_layout

\begin_layout Standard
In global scheduling, a single queue of tasks is dispatched among the processors.
 Global scheduling protocols traditionally have an EDF policy.
\end_layout

\begin_layout Paragraph
Partitioned scheduling protocols
\end_layout

\begin_layout Standard
In partitioned scheduling each task is statically assigned a processor e.g.
 migrations between processors are not allowed.
 Each processor is scheduled independently.
 In other words partitioning reduces the multiprocessor scheduling problem
 to a set of uniprocessor
\begin_inset CommandInset citation
LatexCommand cite
key "carpenter2004categorization"

\end_inset

.
 This form of scheduling is the most used because it reuses well-known concepts
 of uniprocessor scheduling.
\end_layout

\begin_layout Paragraph
Semi-partitioned protocols
\end_layout

\begin_layout Standard
Semi-partitioned protocols are a compromise between global and partitioned
 protocols.
 Processors are grouped into subsets.
 A task is statically assigned to a set of processors.
 Each subset is then scheduled globally.
 
\end_layout

\begin_layout Subsection
Problems and Concepts in Real-time Resource Sharing Protocols 
\end_layout

\begin_layout Standard
Computing programs (tasks) are composed of sequences of actions to execute
 to perform a task or provide a service.
\end_layout

\begin_layout Standard
The actions are computer instructions executed by the processor in a sequential
 fashion.
 Only one action of one task can be executed at a time.
 Tasks execution can be safely interleaved as long as a switching and preempting
 between different tasks is done between any two atomic instructions.
 Tasks are assigned a priority level to enable prioritised scheduling where
 higher tasks are given more processor time with less waiting time.
\end_layout

\begin_layout Standard
Programs necessarily share resources because resources are available in
 limited amount and/or they are used as a communication channel to communicate
 with other programs.
 Resource access is therefore a crucial part of task scheduling.
 Often resources can not be accessed by two tasks at the same time.
 Two different tasks might both be trying to update a resource at the same
 time, this is called a race condition and if not prevented, there is a
 risk of leaving the resource in a corrupted state and source of computing
 errors.
\end_layout

\begin_layout Standard
To prevent race condition, mutual exclusion techniques have been introduced.
 Semaphores are the generic construct that enables task suspension when
 an access request to a resource currently used therefore providing a mutual
 exclusion service to protect resources state.
 While semaphores are perfectly suited for traditional systems, real-time
 systems have deadline constraints and predictability of task execution
 is crucial (response time).
 While solving the race condition situation, simple semaphores used in real-time
 systems are not sufficient to fulfill the requirements and they introduce
 new problems, priority inversion and unbounded priority inversion.
 Real time resource sharing protocols are designed to mitigate or address
 these issues.
\end_layout

\begin_layout Subparagraph

\series bold
Priority Inversion 
\end_layout

\begin_layout Standard

\series bold
Mars Path Finder famous priority inversion
\end_layout

\begin_layout Standard
Priority inversion is a situation where a higher priority task gets preempted
 or has its execution delayed by a lower priority task.
 For instance given H and L respectively tasks of high and low priority,
 consider : L accesses a resource R, H is released and wants to access R,
 it has to wait until L is finished with it (Priority Inversion).
 Priority inversion is normal and unavoidable in scheduling because predicting
 when two tasks of different priorities will access the same mutually exclusive
 area or resource is hard [EXAMPLE] or impossible.
 It is however possible to minimize its effects and thus increase predictability.
\end_layout

\begin_layout Subparagraph
Unbounded priority inversion
\end_layout

\begin_layout Standard
Extending the previous priority inversion example, let's introduce another
 task M of intermediate priority between H and L.
 While H is waiting, M gets released and preempts L, H has now to wait for
 M + L execution time, moreover M could itself be preempted by a second
 task M2 slightly higher than M but lower than H.
 
\end_layout

\begin_layout Standard
Unbounded priority inversion can and must be avoided because they severely
 impede predictability Priority inheritance described further is one method
 to minimize the effects of priority inversion.
\end_layout

\begin_layout Standard

\series bold
The major problems these protocols intend to solve are : 
\end_layout

\begin_layout Subparagraph

\series bold
Deadlocks (nested resources)
\end_layout

\begin_layout Standard
Deadlock is a task and resource configuration where two tasks or more are
 holding a resource and each is respectively waiting on the other to release
 its resource.
 The result is that each task waits forever and cannot continue its execution.
 Resource sharing protocols will sometimes try to prevent that situation,
 however it is often the user's duty to ensure it doesn't happen by following
 good programming practices.
 Often deadlock situations are created when locks are not taken in the same
 order.
\end_layout

\begin_layout Subparagraph

\series bold
Resource starvation
\end_layout

\begin_layout Standard

\series bold
[Round-Robin ?]
\end_layout

\begin_layout Standard
In a system where tasks are competing for resources access, resource starvation
 occurs when a task's request to access to a resource is never satisfied
 by the scheduler.
 Therefore that task cannot make progress and blocks forever.
 Resource starvation appears when for instance the scheduler schedules the
 execution of tasks without ensuring fairness between threads.
 
\end_layout

\begin_layout Standard
The readers-writers problem illustrates well that situation, the terms of
 the problem are as follows : 
\end_layout

\begin_layout Itemize
There is a resource R which many writer tasks are allowed to use, as well
 as many reader tasks.
 
\end_layout

\begin_layout Itemize
Readers and writers are not allowed access at the same time.
 
\end_layout

\begin_layout Itemize
Two or more readers can access R at the same time.
\end_layout

\begin_layout Itemize
Writers can only access R individually
\end_layout

\begin_deeper
\begin_layout Standard
While writers requesting access have to do it by turn and wait for each
 other to release the resource, readers don't have to wait.
 Naive attempts to solve this problem such as letting readers access the
 resource without taking into account waiting writers can result in resource
 starvation for writers.
\end_layout

\end_deeper
\begin_layout Standard

\series bold
Deadline Inversion
\end_layout

\begin_layout Standard

\series bold
A task with short deadline is blocked by a task with longer deadline for
 an unbounded interval of time.
 
\end_layout

\begin_layout Standard
==================
\end_layout

\begin_layout Standard

\series bold
Concepts
\end_layout

\begin_layout Subparagraph

\series bold
Local Or Global Resources
\end_layout

\begin_layout Standard
Some scheduling protocols classify resources as being global or local.
 Global resources can be accessed by all the tasks while local resources
 can only be accessed on specific processors to whom they are assigned.
 
\end_layout

\begin_layout Standard
Example of resources :
\end_layout

\begin_layout Itemize
Variables in memory (RAM, hard-disk, processor cache )
\end_layout

\begin_layout Itemize
Hardware device or appliance (fax, printer) 
\end_layout

\begin_layout Itemize
Connection channel 
\end_layout

\begin_layout Itemize
Database
\end_layout

\begin_layout Subparagraph

\series bold
Suspend based or Spin based waiting
\end_layout

\begin_layout Standard
Scheduling protocols can be suspend-based or spin-based when wanting to
 acquire a resource.
 Suspend-based means that task relinquish the processor and become idle
 until the resource becomes free.
 Spin-based means that task continue their execution, continuously checking
 if the resource has become free.
 Suspend-based is the most encountered model in the userspace however spinning
 is widely used at kernel level.
 The typical suspend based structure is the mutex, the typical spin based
 structure is the spinlock.
\end_layout

\begin_layout Subparagraph

\series bold
Schedulability Analysis (Response Time Analysis)
\end_layout

\begin_layout Standard
Real-time systems have response time and timings that must be guaranteed,
 schedulability analysis is a mathematical method designed to prove the
 scheduler correctness for a configuration of tasks and resources given
 their priority and deadlines.
 Such configuration can be proven to be schedulable, which means that all
 tasks in that configuration are guaranteeed to meet their deadlines.
 While an analysis can be sufficient to prove a set of task and resources
 to be schedulable, not all configuration of tasks and resources can be
 proved.
 Schedulability analysis can be applied to fixed-priority (FP) or earliest-deadl
ine-first (EDF) systems.
\end_layout

\begin_layout Standard

\series bold
Transitive blocking
\series default
 
\end_layout

\begin_layout Standard
By not-directly involved semaphores which are accessed in a nested form
 by blocking jobs.
 Transitive blocking is said to occur if a job J is blocked by J1 which,
 in turn, is blocked by another job J2 
\end_layout

\begin_layout Standard

\series bold
Fixed Priority (FP)
\end_layout

\begin_layout Standard
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard

\series bold
Earliest Deadline First (EDF)
\end_layout

\begin_layout Standard
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard

\series bold
The performance parameter are:
\end_layout

\begin_layout Enumerate

\series bold
Contention of High priority threads
\end_layout

\begin_layout Standard
Mutual exclusion to a critical section may be implemented on a uniprocessor
 (UP) system by simply preventing the thread that accesses the section from
 being preempted.
 On a symmetric multiprocessor (SMP) system, disabling pre- emption is not
 enough.
 A thread on another CPU might access the critical section.
 [Internal RT paper]
\end_layout

\begin_layout Standard
____________________
\end_layout

\begin_layout Standard
Spin_locks are relatively fast.
 The idea behind a spin_lock is to protect critical sections that are very
 short.
 A spin_lock is considered fast compared to suspend-based locks because
 it avoids the overhead of a re-schedule.
 [Internal RT papers]
\end_layout

\begin_layout Standard
____________________
\end_layout

\begin_layout Standard
If the time to run the code in a critical section is shorter than the time
 of a context switch, it is reasonable to use a spin_lock, and on contention,
 spin in a busy loop, while waiting for a thread on another CPU to release
 the spin_lock.
 [Internals RT]
\end_layout

\begin_layout Standard
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Subsection

\series bold
Real-time Resource Sharing Uniprocessor Protocols
\end_layout

\begin_layout Subsubsection
Non Preemptive Protocol
\end_layout

\begin_layout Subparagraph

\series bold
Description
\end_layout

\begin_layout Standard
The Non Preemptive Protocol is a simple approach to resource sharing.
 It can be described as follows : when a task enters a mutually exclusive
 area it can't be preempted by any other task.
 We can define it as being an absolute non-preemption scheme when a any
 lock is held by any task.
\end_layout

\begin_layout Subparagraph
Example
\end_layout

\begin_layout Standard
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard
Resources : 
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard

\series bold
R1
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard
Resource access :
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $\left\{ HP\rightarrow none\right\} $
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $\left\{ MP\rightarrow none\right\} $
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $\left\{ LP\rightarrow R1\right\} $
\end_inset


\end_layout

\begin_layout Standard
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newganttlinktypealias{sta-to-sta}{s-s}
\end_layout

\begin_layout Plain Layout


\backslash
newganttlinktypealias{fin-to-fin}{f-f}
\end_layout

\begin_layout Plain Layout


\backslash
newganttlinktypealias{fin-to-sta}{f-s}
\end_layout

\begin_layout Plain Layout


\backslash
setganttlinklabel{fin-to-fin}{f2f}
\end_layout

\begin_layout Plain Layout


\backslash
setganttlinklabel{fin-to-sta}{}
\end_layout

\begin_layout Plain Layout


\backslash
begin{figure}[h]
\end_layout

\begin_layout Plain Layout


\backslash
begin{ganttchart}[
\end_layout

\begin_layout Plain Layout

hgrid,
\end_layout

\begin_layout Plain Layout

vgrid={*1{red, dotted}}, 
\end_layout

\begin_layout Plain Layout

title height=1,
\end_layout

\begin_layout Plain Layout

include title in canvas=true,
\end_layout

\begin_layout Plain Layout

bar/.append style={fill=green!75},
\end_layout

\begin_layout Plain Layout

%bar height=.5,
\end_layout

\begin_layout Plain Layout

bar label font=
\backslash
normalsize
\backslash
color{black!50}]{1}{20}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=gray!75}]{
\backslash
small{HP Task}}{4}{8}
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=green!75}]{}{9}{15}
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=gray!75}]{
\backslash
small{MP Task}}{7}{15} 
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=green!75}]{}{16}{17}
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=green!75}]{
\backslash
small{LP Task}}{1}{2}
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=red!75}]{}{3}{8}
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=green!75}]{}{18}{19}
\backslash

\backslash

\end_layout

\begin_layout Plain Layout

%
\backslash
ganttlink[link type=fin-to-sta]{elem1}{elem0}
\end_layout

\begin_layout Plain Layout

%
\backslash
ganttlink[link type=fin-to-sta]{elem2}{elem1}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
gantttitlelist{1,...,20}{1}//
\end_layout

\begin_layout Plain Layout


\backslash
end{ganttchart}
\end_layout

\begin_layout Plain Layout


\backslash
caption{Non-Preemptive Protocol}
\end_layout

\begin_layout Plain Layout


\backslash
end{figure}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Enumerate
T1 : Low priority task starts to execute 
\end_layout

\begin_layout Enumerate
T3 : LP locks shared resource R1 
\end_layout

\begin_layout Enumerate
T4 - T8 : High priority task is ready to execute but is blocked by LP because
 preemption is disabled when any task has entered a critical section.
\end_layout

\begin_layout Enumerate
T7 : Medium priority task is ready to execute but is preempted by LP.
\end_layout

\begin_layout Enumerate
T8 : LP releases R1
\end_layout

\begin_layout Enumerate
T9 : HP preempts LP
\end_layout

\begin_layout Enumerate
T15 : HP finishes its execution
\end_layout

\begin_layout Enumerate
T16-17 : MP executes and finishes
\end_layout

\begin_layout Enumerate
T18-19 : LP task finishes its execution
\end_layout

\begin_layout Standard

\series bold
Advantages
\end_layout

\begin_layout Itemize
The implementation of the non-preemptive protocol is very simple.
 
\end_layout

\begin_layout Itemize
Good when access to resources are (very) short.
\end_layout

\begin_layout Subparagraph

\series bold
Limitations
\end_layout

\begin_layout Itemize
This protocol allows low priority tasks to block higher priority tasks that
 are not even requiring access to shared resources which is a form of priority
 inversion.
 
\end_layout

\begin_layout Subsubsection
Priority Inheritance Protocol
\end_layout

\begin_layout Standard
In the Non-Preemptive Protocol deadline misses can occur frequently since
 all tasks are blocked when a critical section is entered.
 The Priority Inheritance Protocol (PIP) intends to correct that by introducing
 priority inheritance.
 The aim is to reduce blocking time for high priority tasks.
 PIP can be defined as a relative non-preemption scheme : a lower task holding
 a lock becomes non-preemptable relatively to the higher task it blocks,
 an unrelated even higher task won't be blocked.
 
\end_layout

\begin_layout Subparagraph
Description
\end_layout

\begin_layout Itemize
Tasks have an original priority.
\end_layout

\begin_layout Itemize
Propagation of priority (e.g priority inheritance) : when a lower priority
 task C holds a resource needed by a higher priority task A, C inherits
 the priority of A.
\end_layout

\begin_layout Itemize
Transitive propagation of inheritance : If task C blocks task B which is
 itself blocking task A then C inherits the priority of A.
\end_layout

\begin_layout Itemize
Tasks are set back to original priority upon leaving a critical section.
\end_layout

\begin_layout Standard
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Subparagraph
Example
\end_layout

\begin_layout Standard
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard
Resources : 
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard

\series bold
R1
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard
Resource access :
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $\left\{ HP\rightarrow R1\right\} $
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $\left\{ MP\rightarrow none\right\} $
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $\left\{ LP\rightarrow R1\right\} $
\end_inset


\end_layout

\begin_layout Standard
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newganttlinktypealias{sta-to-sta}{s-s}
\end_layout

\begin_layout Plain Layout


\backslash
newganttlinktypealias{fin-to-fin}{f-f}
\end_layout

\begin_layout Plain Layout


\backslash
newganttlinktypealias{fin-to-sta}{f-s}
\end_layout

\begin_layout Plain Layout


\backslash
setganttlinklabel{fin-to-fin}{f2f}
\end_layout

\begin_layout Plain Layout


\backslash
setganttlinklabel{fin-to-sta}{}
\end_layout

\begin_layout Plain Layout


\backslash
begin{figure}[h]
\end_layout

\begin_layout Plain Layout


\backslash
begin{ganttchart}[
\end_layout

\begin_layout Plain Layout

hgrid,
\end_layout

\begin_layout Plain Layout

vgrid={*1{red, dotted}}, 
\end_layout

\begin_layout Plain Layout

title height=1,
\end_layout

\begin_layout Plain Layout

include title in canvas=true,
\end_layout

\begin_layout Plain Layout

bar/.append style={fill=green!75},
\end_layout

\begin_layout Plain Layout

%bar height=.5,
\end_layout

\begin_layout Plain Layout

bar label font=
\backslash
normalsize
\backslash
color{black!50}]{1}{20}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=green!75}]{
\backslash
small{HP Task}}{4}{4}
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=gray!75}]{}{5}{7}
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=red!75}]{}{8}{11}
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=green!75}]{}{12}{14}
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=gray!75}]{
\backslash
small{MP Task}}{6}{16} 
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=green!75}]{}{15}{17}
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=green!75}]{
\backslash
small{LP Task}}{1}{2}
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=red!75}]{}{3}{3}
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=red!75}]{}{5}{7}
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=green!75}]{}{18}{20}
\backslash

\backslash

\end_layout

\begin_layout Plain Layout

%
\backslash
ganttlink[link type=fin-to-sta]{elem1}{elem0}
\end_layout

\begin_layout Plain Layout

%
\backslash
ganttlink[link type=fin-to-sta]{elem2}{elem1}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
gantttitlelist{1,...,20}{1}//
\end_layout

\begin_layout Plain Layout


\backslash
end{ganttchart}
\end_layout

\begin_layout Plain Layout


\backslash
caption{Priority Inheritance Protocol}
\end_layout

\begin_layout Plain Layout


\backslash
end{figure}
\end_layout

\end_inset


\end_layout

\begin_layout Subparagraph
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Enumerate
T1-T2 : LP starts executing 
\end_layout

\begin_layout Enumerate
T3 : LP locks shared resource R1
\end_layout

\begin_layout Enumerate
T4 : HP requires access to R1, LP is preempted by HP, however HP can't lock
 R1
\end_layout

\begin_layout Enumerate
as it is already held by LP.
 LP inherits the priority of HP.
\end_layout

\begin_layout Enumerate
T5 : LP resumes executing in critical section
\end_layout

\begin_layout Enumerate
T6 : MP is spawned and ready to execute, however it can't preempt LP that
 is
\end_layout

\begin_layout Enumerate
running with HP priority
\end_layout

\begin_layout Enumerate
T7 : LP releases R1 and is set back to its original low priority
\end_layout

\begin_layout Enumerate
T8-T11 : HP locks R1 and executes.
\end_layout

\begin_layout Enumerate
T12-T14 : HP releases R1 in T12 and continues executing until T14
\end_layout

\begin_layout Enumerate
T15-T17 : MP runs as it has higher priority than LP
\end_layout

\begin_layout Enumerate
T18-T20 : LP can run again and finishes its execution in T20
\end_layout

\begin_layout Subparagraph
Advantages
\end_layout

\begin_layout Itemize
Bounded Priority Inversion
\end_layout

\begin_layout Subparagraph
Limitations
\end_layout

\begin_layout Itemize
Does not prevent deadlocks when locks are not taken in the same order (see
 Figure [NUMBER])
\end_layout

\begin_layout Itemize
Does not prevent chained blocking : High task needs resources R1 then R2
 which are held by two different lower tasks, the higher task has to wait
 for both lower priority tasks.
\end_layout

\begin_layout Standard
Two types of blocking are distinguished in this protocol :
\end_layout

\begin_layout Enumerate
Direct blocking : a lower task holding a resource blocks a higher task requestin
g access to that resource.
\end_layout

\begin_layout Enumerate
Priority Inheritance blocking : a medium task is blocked by a lower task
 that temporarily inherited a higher priority.
\end_layout

\begin_layout Subsubsection
The Priority Ceiling Protocol
\end_layout

\begin_layout Standard
The Priority Inheritance protocol solves the problem of unbounded priority
 inversion, however deadlocks and chained blocking are no prevented.
 The intent of the Priority Ceiling Protocol is to mitigate the limitations
 of the Priority Inheritance Protocol.
 It does so by having an 
\shape italic
ungreedy 
\shape default
approach to resources lock request that prevents the apparition of certain
 tasks and resources configuration that leads to unnecessary blocking or
 deadlocks.
\end_layout

\begin_layout Subparagraph
Description
\end_layout

\begin_layout Itemize
Each resource has a ceiling value defined as the maximum priority of all
 tasks that use it defined as PR.
\end_layout

\begin_layout Itemize
A new parameter is introduced : the highest ceiling of all locked resources
 at a given time defined as C.
\end_layout

\begin_layout Itemize
A task resource usage is known offline (before the tasks's execution).
\end_layout

\begin_layout Itemize
A task is allowed to enter a critical section only if its priority is strictly
 higher than C (thus avoiding chained blocking)
\end_layout

\begin_layout Standard
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Subparagraph
Example
\end_layout

\begin_layout Standard
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard
Resources :
\end_layout

\begin_layout Standard
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard
R1, R2 and R3
\end_layout

\begin_layout Standard
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard
Resource Access :
\end_layout

\begin_layout Standard
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $\left\{ HP\rightarrow R1\, then\, R2\right\} $
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $\left\{ MP\rightarrow R3\right\} $
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $\left\{ LP\rightarrow R3\, then\, R2\right\} $
\end_inset


\end_layout

\begin_layout Standard
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard
Resource priority ceilings :
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $\left\{ PR(R1)\right\} =PR(HP)$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $\left\{ PR(R2)=PR(HP)\right\} $
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $\left\{ PR(R3)=PR(MP)\right\} $
\end_inset


\end_layout

\begin_layout Standard
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newganttlinktypealias{sta-to-sta}{s-s}
\end_layout

\begin_layout Plain Layout


\backslash
newganttlinktypealias{fin-to-fin}{f-f}
\end_layout

\begin_layout Plain Layout


\backslash
newganttlinktypealias{fin-to-sta}{f-s}
\end_layout

\begin_layout Plain Layout


\backslash
setganttlinklabel{fin-to-fin}{f2f}
\end_layout

\begin_layout Plain Layout


\backslash
setganttlinklabel{fin-to-sta}{}
\end_layout

\begin_layout Plain Layout


\backslash
begin{figure}[h]
\end_layout

\begin_layout Plain Layout


\backslash
newganttlinktypealias{sta-to-sta}{s-s}
\end_layout

\begin_layout Plain Layout


\backslash
newganttlinktypealias{fin-to-fin}{f-f}
\end_layout

\begin_layout Plain Layout


\backslash
newganttlinktypealias{fin-to-sta}{f-s}
\end_layout

\begin_layout Plain Layout


\backslash
setganttlinklabel{fin-to-fin}{f2f}
\end_layout

\begin_layout Plain Layout


\backslash
setganttlinklabel{fin-to-sta}{}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
begin{ganttchart}[
\end_layout

\begin_layout Plain Layout

hgrid,
\end_layout

\begin_layout Plain Layout

vgrid={*1{red, dotted}}, 
\end_layout

\begin_layout Plain Layout

title height=1,
\end_layout

\begin_layout Plain Layout

include title in canvas=true,
\end_layout

\begin_layout Plain Layout

bar/.append style={fill=green!75},
\end_layout

\begin_layout Plain Layout

%bar height=.5,
\end_layout

\begin_layout Plain Layout

bar label font=
\backslash
tiny
\backslash
color{black!50}]{1}{20}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[]{
\backslash
small{System ceiling}}{1}{1}
\end_layout

\begin_layout Plain Layout


\backslash
gantttitle[title label font=
\backslash
scriptsize]{MP}{1}
\end_layout

\begin_layout Plain Layout


\backslash
gantttitle[title label font=
\backslash
scriptsize]{MP}{1}
\end_layout

\begin_layout Plain Layout


\backslash
gantttitle[title label font=
\backslash
scriptsize]{MP}{1}
\end_layout

\begin_layout Plain Layout


\backslash
gantttitle[title label font=
\backslash
scriptsize]{MP}{1}
\end_layout

\begin_layout Plain Layout


\backslash
gantttitle[title label font=
\backslash
scriptsize]{MP}{1}
\end_layout

\begin_layout Plain Layout


\backslash
gantttitle[title label font=
\backslash
scriptsize]{MP}{1}
\end_layout

\begin_layout Plain Layout


\backslash
gantttitle[title label font=
\backslash
scriptsize]{HP}{1}
\end_layout

\begin_layout Plain Layout


\backslash
gantttitle[title label font=
\backslash
scriptsize]{HP}{1}
\end_layout

\begin_layout Plain Layout


\backslash
gantttitle[title label font=
\backslash
scriptsize]{HP}{1}
\end_layout

\begin_layout Plain Layout


\backslash
gantttitle[title label font=
\backslash
scriptsize]{HP}{1}
\end_layout

\begin_layout Plain Layout


\backslash
gantttitle[title label font=
\backslash
scriptsize]{HP}{1}
\end_layout

\begin_layout Plain Layout


\backslash
gantttitle[title label font=
\backslash
scriptsize]{HP}{1}
\end_layout

\begin_layout Plain Layout


\backslash
gantttitle[title label font=
\backslash
scriptsize]{HP}{1}
\end_layout

\begin_layout Plain Layout


\backslash
gantttitle[title label font=
\backslash
scriptsize]{HP}{1}
\end_layout

\begin_layout Plain Layout


\backslash
gantttitle[title label font=
\backslash
scriptsize]{HP}{1}
\end_layout

\begin_layout Plain Layout


\backslash
gantttitle[title label font=
\backslash
scriptsize]{MP}{1}
\end_layout

\begin_layout Plain Layout


\backslash
gantttitle[title label font=
\backslash
scriptsize]{MP}{1}
\end_layout

\begin_layout Plain Layout


\backslash
gantttitle[title label font=
\backslash
scriptsize]{MP}{1}
\end_layout

\begin_layout Plain Layout


\backslash
gantttitle[title label font=
\backslash
scriptsize]{nil}{1}
\end_layout

\begin_layout Plain Layout


\backslash
gantttitle[title label font=
\backslash
scriptsize]{nil}{1}
\end_layout

\begin_layout Plain Layout


\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=green!75}]{
\backslash
small{HP Task}}{7}{7}
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=gray!75}]{}{8}{9}
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=yellow!75}]{}{10}{11}
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=green!75}]{}{12}{13}
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=orange!75}]{}{13}{14}
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=green!75}]{}{15}{15}
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=green!75}]{
\backslash
small{MP Task}}{3}{3} 
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=gray!75}]{}{4}{16}
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=red!75}]{}{17}{18}
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=green!75}]{}{18}{18}
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=green!75}]{
\backslash
small{LP Task}}{1}{1}
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=red!75}]{}{2}{2}
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=gray!75}]{}{3}{3}
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=red!75}]{}{4}{4}
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=orange!75}]{}{5}{6}
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=gray!75}]{}{7}{7}
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=orange!75}]{}{8}{9}
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=red!75}]{}{16}{16}
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=green!75}]{}{19}{20}
\backslash

\backslash

\end_layout

\begin_layout Plain Layout

%
\backslash
ganttlink[link type=fin-to-sta]{elem1}{elem0}
\end_layout

\begin_layout Plain Layout

%
\backslash
ganttlink[link type=fin-to-sta]{elem2}{elem1}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
gantttitlelist{1,...,20}{1}//
\end_layout

\begin_layout Plain Layout


\backslash
end{ganttchart}
\end_layout

\begin_layout Plain Layout


\backslash
caption{Priority Ceiling Protocol}
\end_layout

\begin_layout Plain Layout


\backslash
end{figure}
\end_layout

\end_inset


\end_layout

\begin_layout Enumerate
T1 : LP starts executing and locks R3, system ceiling is nil.
\end_layout

\begin_layout Enumerate
T2 : System ceiling is set to PR(R3) = PR(MP), LP locks R3.
\end_layout

\begin_layout Enumerate
T3 : MP preempts LP as it has higher priority.
\end_layout

\begin_layout Enumerate
T4 : MP needs to lock R3 but PR(MP) is not strictly higher than C (system
 ceiling) LP therefore it relinquishes the CPU and LP inherits PR(MP).
 
\end_layout

\begin_layout Enumerate
T5-T6 : LP locks R2, C is set to PR(HP) and makes progress in its execution.
\end_layout

\begin_layout Enumerate
T7 : HP preempts LP as is has higher priority.
\end_layout

\begin_layout Enumerate
T8-T9 : HP needs to lock R2 but PR(HP) is not strictly higher than C, it
 therefore relinquishes the CPU and PR(LP) becomes PR(HP).
 LP continues its execution.
\end_layout

\begin_layout Enumerate
T10-T11 : LP releases R2 and its priority is set to PR(MP).
 HP preempts LP, locks R1 and makes progress.
\end_layout

\begin_layout Enumerate
T12 : HP releases R1 and continues executing.
\end_layout

\begin_layout Enumerate
T13-T14 : HP locks R2 and progresses.
\end_layout

\begin_layout Enumerate
T15 : HP releases R2 and resumes.
 C is set to PR(MP)
\end_layout

\begin_layout Enumerate
T16 : LP executes and releases R3, its priority is set back to its original
 level.
 C is set to nil.
\end_layout

\begin_layout Enumerate
T17 : MP preempts LP and locks R3.
\end_layout

\begin_layout Enumerate
T18 : MP unlocks R3 and resumes.
\end_layout

\begin_layout Enumerate
T19-T20 : LP executes and resumes.
 
\end_layout

\begin_layout Subparagraph
Advantages
\end_layout

\begin_layout Itemize
Prevents deadlocks.
\end_layout

\begin_layout Itemize
Prevents transitive blocking.
\end_layout

\begin_layout Itemize
Prevents chained blocking.
\end_layout

\begin_layout Itemize
The maximum blocking delay for a task is bounded by the duration of the
 longest critical section among those of lower priority tasks.
\end_layout

\begin_layout Subparagraph
Limitations
\end_layout

\begin_layout Itemize
Introduces a new type of blocking : priority ceiling blocking [Explain]
\end_layout

\begin_layout Itemize
Increases the number of context switches (it is time consuming to switch
 and load a different context)
\end_layout

\begin_layout Itemize
Implementation is complex
\end_layout

\begin_layout Subsubsection
Immediate Priority Ceiling Protocol
\end_layout

\begin_layout Standard
The Immediate Priority Ceiling Protocol is a simplified version of the Priority
 Ceiling Protocol.
 While keeping all the advantages of PCP, it aims to decrease the number
 of context switches.
\end_layout

\begin_layout Standard

\series bold
Description
\end_layout

\begin_layout Itemize
Each task has a default original priority.
\end_layout

\begin_layout Itemize
A task's priority is raised to the resource ceiling immediately upon ownership
 acquisition.
\end_layout

\begin_layout Standard
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newganttlinktypealias{sta-to-sta}{s-s}
\end_layout

\begin_layout Plain Layout


\backslash
newganttlinktypealias{fin-to-fin}{f-f}
\end_layout

\begin_layout Plain Layout


\backslash
newganttlinktypealias{fin-to-sta}{f-s}
\end_layout

\begin_layout Plain Layout


\backslash
setganttlinklabel{fin-to-fin}{f2f}
\end_layout

\begin_layout Plain Layout


\backslash
setganttlinklabel{fin-to-sta}{}
\end_layout

\begin_layout Plain Layout


\backslash
begin{figure}[h]
\end_layout

\begin_layout Plain Layout


\backslash
begin{ganttchart}[
\end_layout

\begin_layout Plain Layout

hgrid,
\end_layout

\begin_layout Plain Layout

vgrid={*1{red, dotted}}, 
\end_layout

\begin_layout Plain Layout

title height=1,
\end_layout

\begin_layout Plain Layout

include title in canvas=true,
\end_layout

\begin_layout Plain Layout

bar/.append style={fill=green!75},
\end_layout

\begin_layout Plain Layout

%bar height=.5,
\end_layout

\begin_layout Plain Layout

bar label font=
\backslash
normalsize
\backslash
color{black!50}]{1}{20}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=gray!75}]{
\backslash
small{HP Task}}{4}{8}
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=green!75}]{}{9}{15}
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=gray!75}]{
\backslash
small{MP Task}}{11}{15} 
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=green!75}]{}{16}{17}
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=green!75}]{
\backslash
small{LP Task}}{1}{2}
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=red!75}]{}{3}{8}
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=green!75}]{}{18}{19}
\backslash

\backslash

\end_layout

\begin_layout Plain Layout

%
\backslash
ganttlink[link type=fin-to-sta]{elem1}{elem0}
\end_layout

\begin_layout Plain Layout

%
\backslash
ganttlink[link type=fin-to-sta]{elem2}{elem1}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
gantttitlelist{1,...,20}{1}//
\end_layout

\begin_layout Plain Layout


\backslash
end{ganttchart}
\end_layout

\begin_layout Plain Layout


\backslash
caption{Immediate Priority Ceiling Protocol}
\end_layout

\begin_layout Plain Layout


\backslash
end{figure}
\end_layout

\end_inset


\end_layout

\begin_layout Subparagraph

\series bold
Advantages
\end_layout

\begin_layout Itemize
Same advantages as PCP
\end_layout

\begin_layout Itemize
Additional advantage of less context switches
\end_layout

\begin_layout Subparagraph

\series bold
Performance
\end_layout

\begin_layout Standard
Same worst case performance as the Priority Ceiling Protocol
\end_layout

\begin_layout Standard
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard

\series bold
Limitations
\end_layout

\begin_layout Itemize
A higher number of tasks priority changes is traded for less context switches,
 in most computer and operating systems architecture this is beneficial.
\end_layout

\begin_layout Itemize
Early blocking of tasks causes more deadline misses (even tasks that require
 no shared resources.)
\end_layout

\begin_layout Subsubsection
Stack Resource Policy
\end_layout

\begin_layout Standard
The Stack Resource Policy intends to reduce the number of context switches
 introduced by PCP by anticipating the execution order of tasks.
 It generalises the concept of task priority by defining a 
\shape italic
preemption level 
\shape default
corresponding to the task priority in FP systems and to the inversely proportion
al task deadline (the closer the deadline the higher the preemption level).
\end_layout

\begin_layout Standard
In this protocol, a task is not allowed to execute until the resources it
 needs are available.
 Traditionally in scheduling protocols, each task has a private stack where
 subroutines calls are pushed and popped to keep track of its current progress.
 On the SRP tasks can share their stack.
 Each resource is assigned a maximum ceiling (maximum priority of all tasks
 using it).
 
\end_layout

\begin_layout Subparagraph
Description
\end_layout

\begin_layout Itemize
Each task is assigned a fixed preemption level
\end_layout

\begin_layout Itemize
Each resource is assigned a preemption ceiling that corresponds to the maximum
 preemption level of all tasks using that resource
\end_layout

\begin_layout Itemize
When a task locks a resource its priority get raised to the resource ceiling
 priority
\end_layout

\begin_layout Itemize
The system ceiling is the maximum preemption ceiling among all currently
 locked resource.
\end_layout

\begin_layout Itemize
A task is not allowed to run until its priority is highest among the tasks
 ready to run and its preemption level is higher than the system ceiling.
\end_layout

\begin_layout Itemize
Tasks ready to be executed are added to the stack
\end_layout

\begin_layout Itemize
Tasks execution is not interleaved
\end_layout

\begin_layout Standard
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard
Example
\end_layout

\begin_layout Standard
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard
Resources : 
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard

\series bold
R1, R2
\end_layout

\begin_layout Standard
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard
Resource access :
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $\left\{ HP\rightarrow R1\: then\, R2\right\} $
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $\left\{ MP\rightarrow R2\, then\, R1\right\} $
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $\left\{ LP\rightarrow R1\right\} $
\end_inset


\end_layout

\begin_layout Standard
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard
Let P be the priority ceiling of a resource or a task we thus have :
\end_layout

\begin_layout Standard
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $\left\{ P(R1\text{)}=P(R2)=P(HP)\right\} $
\end_inset


\end_layout

\begin_layout Standard
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newganttlinktypealias{sta-to-sta}{s-s}
\end_layout

\begin_layout Plain Layout


\backslash
newganttlinktypealias{fin-to-fin}{f-f}
\end_layout

\begin_layout Plain Layout


\backslash
newganttlinktypealias{fin-to-sta}{f-s}
\end_layout

\begin_layout Plain Layout


\backslash
setganttlinklabel{fin-to-fin}{f2f}
\end_layout

\begin_layout Plain Layout


\backslash
setganttlinklabel{fin-to-sta}{}
\end_layout

\begin_layout Plain Layout


\backslash
begin{figure}[h]
\end_layout

\begin_layout Plain Layout


\backslash
newganttlinktypealias{sta-to-sta}{s-s}
\end_layout

\begin_layout Plain Layout


\backslash
newganttlinktypealias{fin-to-fin}{f-f}
\end_layout

\begin_layout Plain Layout


\backslash
newganttlinktypealias{fin-to-sta}{f-s}
\end_layout

\begin_layout Plain Layout


\backslash
setganttlinklabel{fin-to-fin}{f2f}
\end_layout

\begin_layout Plain Layout


\backslash
setganttlinklabel{fin-to-sta}{}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
begin{ganttchart}[
\end_layout

\begin_layout Plain Layout

hgrid,
\end_layout

\begin_layout Plain Layout

vgrid={*1{red, dotted}}, 
\end_layout

\begin_layout Plain Layout

title height=1,
\end_layout

\begin_layout Plain Layout

include title in canvas=true,
\end_layout

\begin_layout Plain Layout

bar/.append style={fill=green!75},
\end_layout

\begin_layout Plain Layout

%bar height=.5,
\end_layout

\begin_layout Plain Layout

bar label font=
\backslash
normalsize
\backslash
color{black!50}]{1}{20}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=gray!75}]{
\backslash
small{HP Task}}{5}{6}
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=red!75}]{}{7}{8}
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=yellow!75}]{}{9}{11}
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=green!75}]{}{12}{12}
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=gray!75}]{
\backslash
small{MP Task}}{3}{12} 
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=green!75}]{}{13}{13}
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=yellow!75}]{}{14}{16}
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=red!75}]{}{17}{17}
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=green!75}]{}{18}{18}
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=green!75}]{
\backslash
small{LP Task}}{1}{1}
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=red!75}]{}{2}{6}
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=gray!75}]{}{7}{9}
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=green!75}]{}{19}{20}
\backslash

\backslash

\end_layout

\begin_layout Plain Layout

%
\backslash
ganttlink[link type=fin-to-sta]{elem1}{elem0}
\end_layout

\begin_layout Plain Layout

%
\backslash
ganttlink[link type=fin-to-sta]{elem2}{elem1}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
gantttitlelist{1,...,20}{1}//
\end_layout

\begin_layout Plain Layout


\backslash
end{ganttchart}
\end_layout

\begin_layout Plain Layout


\backslash
caption{Stack Resource Protocol}
\end_layout

\begin_layout Plain Layout


\backslash
end{figure}
\end_layout

\end_inset


\end_layout

\begin_layout Enumerate
T1 : LP starts executing
\end_layout

\begin_layout Enumerate
T2 : LP is the only task running, it can then lock R1 and its priority is
 now equal to P(HP)
\end_layout

\begin_layout Enumerate
T3 : MP is ready to execute however P(MP) < P(LP) = P(R1) = P(HP), therefore
\end_layout

\begin_layout Enumerate
it cannot preempt LP
\end_layout

\begin_layout Enumerate
T5 : HP is ready to execute however P(HP) = P(LP), therefore it cannot preempt
 LP
\end_layout

\begin_layout Enumerate
T6 : LP releases the locks and is reset to its initial priority
\end_layout

\begin_layout Enumerate
T7-T11 : P(HP) > P(MP), thus HP is given priority and can lock R1 and R2
 and release them both
\end_layout

\begin_layout Enumerate
T12 : HP continues execution normally as its priority is the highest
\end_layout

\begin_layout Enumerate
T13 - T18 : MP is chosen to continue execution because P(MP) > P(LP)
\end_layout

\begin_layout Enumerate
T19-T20 : LP can finish its execution
\end_layout

\begin_layout Subparagraph
Advantages
\end_layout

\begin_layout Itemize
Limits blocking to only once like PCP, thus reducing context switching.
 
\end_layout

\begin_layout Itemize
Prevents deadlocks.
\end_layout

\begin_layout Itemize
Considering the two previous statements, the maximum blocking time for task
 equals to at most the length of one critical section.
\end_layout

\begin_layout Itemize
Easier to implement (than PCP) as no need for inheritance, no need to block
 tasks in waiting queues, all tasks share the same stack thus optimising
 execution times
\end_layout

\begin_layout Subparagraph

\series bold
Performance
\end_layout

\begin_layout Standard

\series bold
Limitations
\end_layout

\begin_layout Subsection
Real-time Resource Sharing Multiprocessor Protocols
\end_layout

\begin_layout Standard
Local resources can be managed by uniprocessor protocols such as SRP or
 PCP on partitionned systems.
 However when tasks try to access resources shared between many processors
 remote blocking can happen.
 We need protocols able to handle such case.
\end_layout

\begin_layout Subsubsection
The Multiprocessor Priority Ceiling Protocol (MPCP)
\end_layout

\begin_layout Subparagraph
Description
\end_layout

\begin_layout Standard

\series bold
MPCP solves the remote blocking problem [EXPLAIN]
\end_layout

\begin_layout Standard
Rajkumar designed Multiprocessor Priority Ceiling Protocol (MPCP ) 
\series bold
[REF]
\series default
 that extends PCP (Priority Ceiling Protocol).
 Resources are regarded as local or global e.g.
 shared between tasks on different processors.
 Local resources locking is managed using PCP.
 However when acquiring a lock to a global resource, the holding task gets
 its priority raised to a value higher than all running tasks priorities
 in the system.
 If the resource is already held the requesting task is queued to a global
 waiting list and its priority raised to the resource ceiling.
 As noted by 
\begin_inset CommandInset citation
LatexCommand cite
key "davis2011survey"

\end_inset

 while MPCP allows for lower tasks to execute while a global lock is held
 by a task on another processor, this can lead to a further priority inversion
 with a lower task executing taking first a local lock and then a global
 one.
 Even if the resource the higher task is waiting on is released it won't
 be able to execute [GRAPHIC].
\end_layout

\begin_layout Itemize
A task holding a local resource increases its priority only if it blocks
 other tasks.
\end_layout

\begin_layout Itemize
A task holding a local resource inherits the priority of the highest task
 it blocks
\end_layout

\begin_layout Itemize
A task holding a global resource increases its priority immediately to reduce
 remote blocking
\end_layout

\begin_layout Itemize
Resources can be accessed by any processor (shared memory model as opposed
 to distributed memory model)
\end_layout

\begin_layout Itemize
Global resources are assigned a ceiling higher than any other task
\end_layout

\begin_layout Standard
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Subparagraph
Example
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newganttlinktypealias{sta-to-sta}{s-s}
\end_layout

\begin_layout Plain Layout


\backslash
newganttlinktypealias{fin-to-fin}{f-f}
\end_layout

\begin_layout Plain Layout


\backslash
newganttlinktypealias{fin-to-sta}{f-s}
\end_layout

\begin_layout Plain Layout


\backslash
setganttlinklabel{fin-to-fin}{f2f}
\end_layout

\begin_layout Plain Layout


\backslash
setganttlinklabel{fin-to-sta}{}
\end_layout

\begin_layout Plain Layout


\backslash
begin{figure}[h]
\end_layout

\begin_layout Plain Layout


\backslash
begin{ganttchart}[
\end_layout

\begin_layout Plain Layout

hgrid,
\end_layout

\begin_layout Plain Layout

vgrid={*1{red, dotted}}, 
\end_layout

\begin_layout Plain Layout

title height=1,
\end_layout

\begin_layout Plain Layout

include title in canvas=true,
\end_layout

\begin_layout Plain Layout

bar/.append style={fill=green!75},
\end_layout

\begin_layout Plain Layout

%bar height=.5,
\end_layout

\begin_layout Plain Layout

bar label font=
\backslash
normalsize
\backslash
color{black!50}]{1}{20}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=gray!75}]{
\backslash
small{HP Task - P1}}{3}{4}
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=green!75}]{}{5}{5}
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=red!75}]{}{6}{7}
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=green!75}]{}{8}{8}
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=green!75}]{
\backslash
small{LP Task - P1}}{1}{1} 
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=red!75}]{}{2}{4}
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=gray!75}]{}{5}{8}
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=green!75}]{}{9}{9}
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=orange!75}]{}{10}{10}
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=green!75}]{}{11}{11}
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=green!75}]{
\backslash
small{HP Task - P2}}{3}{3}
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=gray!75}]{}{4}{4}
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=red!75}]{}{5}{5}
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=green!75}]{}{6}{7}
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=gray!75}]{}{8}{8}
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=green!75}]{}{9}{10}
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=orange!75}]{}{11}{11}
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=green!75}]{}{12}{13}
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=green!75}]{
\backslash
small{LP Task - P2}}{1}{2}
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=gray!75}]{}{3}{7}
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=red!75}]{}{8}{8}
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=gray!75}]{}{9}{13}
\end_layout

\begin_layout Plain Layout


\backslash
ganttbar[bar/.append style={fill=green!75}]{}{14}{14}
\backslash

\backslash

\end_layout

\begin_layout Plain Layout

%
\backslash
ganttlink[link type=fin-to-sta]{elem1}{elem0}
\end_layout

\begin_layout Plain Layout

%
\backslash
ganttlink[link type=fin-to-sta]{elem2}{elem1}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
gantttitlelist{1,...,20}{1}//
\end_layout

\begin_layout Plain Layout


\backslash
end{ganttchart}
\end_layout

\begin_layout Plain Layout


\backslash
caption{Multiprocessor Priority Ceiling Protovcol}
\end_layout

\begin_layout Plain Layout


\backslash
end{figure}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
In this case, T 1 2 and T 1 4 access global resources directly instead of
 via agents.
 T 1 4 suspends at time 2 since T 1 2 already holds ` 1 .
 Similarly, T 1 2 suspends at time 4 until it holds ` 1 one time unit later.
 Meanwhile, on processor 1, T 1 1 is scheduled at time 5 after T 1 2 returns
 to normal priority and also requests ` 1 at time 6.
 Since resource requests are satised in priority order, T 1 1 's request
 has precedence over T 1 4 's request, which was issued much earlier at
 time 2.
 Thus, T 1 4 must wait until time 8 to access ` 1 .
 Note that T 1 4 preempts T 1 2 when it resumes at time 8 since it is holding
 a global resource.
\end_layout

\begin_layout Subparagraph
Constraints
\end_layout

\begin_layout Itemize
To prevent unbounded priority inversion, local to global and global to global
 nested locks are not allowed.
\end_layout

\begin_layout Itemize
A high priority task blocked on a global resource can be also locally blocked
 by local tasks accessing local resources.
\end_layout

\begin_layout Subparagraph
Performance
\end_layout

\begin_layout Subparagraph
Limitations
\end_layout

\begin_layout Standard
Subject to priority inheritance blocking
\end_layout

\begin_layout Subsubsection
The Multiprocessor Stack Resource Policy (MSRP)
\end_layout

\begin_layout Paragraph
Description
\end_layout

\begin_layout Standard
The Multiprocessor Stack Resource Policy (MRSP) is an extension proposed
 by [REF] of the uniprocessor Stack Resource Policy from [REF] (SRP).
 Each resource is assigned a priority ceiling corresponding to the priority
 level of the higher task using that resource.
 A new M parameter is also introduced, M corresponds to the maximum of all
 the resources ceiling being used at instant T.
 Any task wanting to execute must have a priority higher than M.
\end_layout

\begin_layout Standard
SRP guarantees no blocking when a task is allowed to execute thus enabling
 stack sharing (each task execution is serialized - no interleaving).
\end_layout

\begin_layout Standard
Under MRSP as in MPCP resources are divided into local and global groups.
 Global resources have one ceiling per processor.
 A task on a processor is allowed to execute only if it has the processor
 ceiling priority which preserve the property of non-preemptability once
 a task starts executing.
\end_layout

\begin_layout Standard
Furthermore when a task is blocked on a global resource, it spins non-preemptive
ly to preserve the stack sharing property.
\end_layout

\begin_layout Standard
Tasks accessing nested local and global resources need to be allocated the
 same processor[CHECK].
 
\end_layout

\begin_layout Subparagraph
Constraints
\end_layout

\begin_layout Subparagraph
Performance
\end_layout

\begin_layout Standard
MSRP performs better than MPCP when global critical sections are short and
 access to local resources dominates access to global resources, (which
 is probably the result of good programming practices) [MRSP VS MPCP paper].
 
\end_layout

\begin_layout Subparagraph
Limitations
\end_layout

\begin_layout Subsubsection
The Flexible Multiprocessor Locking Protocol (FMLP) 
\end_layout

\begin_layout Standard
FMLP requires the user to define if resources have long or short access
 times.
 
\end_layout

\begin_layout Standard
Access is differentiated in function of the type of the resource : 
\end_layout

\begin_layout Standard
Short resources benefit from busy-waiting (reduces context-switching) and
 become non-preemptable.
\end_layout

\begin_layout Standard
Long resources are handled through suspend-waiting in a FIFO manner.
 
\end_layout

\begin_layout Standard
A task holding a short resource is not allowed to require access to a long
 resource to avoid deadlock.
 
\end_layout

\begin_layout Paragraph
Description
\end_layout

\begin_layout Paragraph
Constraints
\end_layout

\begin_layout Paragraph
Performance
\end_layout

\begin_layout Standard
FMLP has better performance than MSRP.
 This advantage is at least partly due to the fact that FMLP removes the
 restriction on task allocation required by MSRP 
\begin_inset CommandInset citation
LatexCommand cite
key "davis2011survey"

\end_inset

.
 
\end_layout

\begin_layout Paragraph
Limitations
\end_layout

\begin_layout Subsubsection
Parallel PCP (P-PCP) 
\end_layout

\begin_layout Subsubsection
O(m) Locking Protocol (OMLP) 
\end_layout

\begin_layout Standard
OMLP makes use of a two-level priority queue scheme to allow access to a
 global resource.
 
\end_layout

\begin_layout Standard
Under partitioned scheduling, tasks requiring access to a global resource
 are first put on local priority queue and then in a global prioritized
 queue.
 The highest priority task on the local queue is selected to be put on the
 global queue and its priority is raised to the local ceiling (maximum priority
 being used on the processor) to make it locally non-preemptible, however
 the task might still be suspended if there is high contention on the global
 queue.
\end_layout

\begin_layout Standard
Under global scheduling, tasks requiring access to a 
\end_layout

\begin_layout Subsubsection
M-BWI 
\end_layout

\begin_layout Standard
Many other protocols exist
\end_layout

\begin_layout Subsection
Real-time multiprocessor operating systems
\end_layout

\begin_layout Subsubsection
Characteristics of SMP machines
\end_layout

\begin_layout Subsubsection
Processor Caches
\end_layout

\begin_layout Standard
A processor cache is a fast memory the processor uses to reduce time to
 access memory.
 The cache memory is smaller than the RAM, it is used to stores copies of
 frequently used locations in the RAM.
 Most processors have a two-level cache system L1 (fastest) and L2.
 A processor will typically always check the caches for the data used by
 a task before looking into the RAM.
 A cache miss occurs when the data is not available in any of the caches.
 A process is called 
\shape italic
cache-hot 
\shape default
when it has the requested data in one of the caches.
 Now we can see that the operating system task scheduler will always try
 to have as few cache misses as possible, therefore avoiding slower RAM
 lookups.
\end_layout

\begin_layout Subsubsection
Processor affinity
\end_layout

\begin_layout Standard
Processor affinity enables the pinning of a process or a thread to a processor
 or a set of processors, so that the process will only execute on the designated
 processor set.
 This is however on Linux only a hint to the scheduler and there is no guarantee
 that it will be respected.
 
\end_layout

\begin_layout Subsubsection
Cost of migration 
\end_layout

\begin_layout Standard
The cost of two migrations must be less than the interference of a higher
 priority thread.
 Also a migrating thread is likely to suffer from an execution time penalty
 as its local cache cannot be utilised.
 However, a preempted thread is also likely to have its data in cache overwritte
n by the time it executes again.
 
\end_layout

\begin_layout Subsection
Summary
\end_layout

\begin_layout Section
The Multiprocessor Resource Sharing Protocol
\end_layout

\begin_layout Subsection
Description
\end_layout

\begin_layout Standard
Here we present informally the protocol as it is described in details in
 
\begin_inset CommandInset citation
LatexCommand cite
key "burns2013schedulability"

\end_inset


\end_layout

\begin_layout Standard
We assume a fully partitioned system.
 That is, each thread can only execute on one processor.
 
\end_layout

\begin_layout Enumerate
All mutexes are assigned a set of ceiling priorities, one per processor
 (for those processors that have threads that use the mutex); for processor
 Pk the mutex's priority is the maximum priority of all threads allocated
 to Pk that use the mutex.
 
\end_layout

\begin_layout Enumerate
A lock request on any mutex results in the priority of the thread being
 immediately raised (ICPP) to the local ceiling for the mutex i.e the mutex's
 priority for the processor executing the thread.
\end_layout

\begin_layout Enumerate
Accesses to a mutex are dealt with in a FIFO order.
 
\end_layout

\begin_layout Enumerate
While waiting to gain access to the mutex, and while actually holding the
 mutex, the thread continues to be active and executes (possible spinning)
 with priority equal to the local ceiling of the mutex.
 
\end_layout

\begin_layout Enumerate
Any thread waiting to gain access to a mutex must be capable of undertaking
 the associated computation on behalf of any other waiting thread (SPEPP).
 
\end_layout

\begin_layout Enumerate
This cooperating thread must undertake the outstanding requests in the original
 FIFO order.
 
\end_layout

\begin_layout Subsection
A migration approach
\end_layout

\begin_layout Standard
While the protocol developed is intended for partitioned systems, thread
 migration between processors is common in SMP operating systems.
\end_layout

\begin_layout Standard
Migration-based classification 
\begin_inset CommandInset citation
LatexCommand cite
key "carpenter2004categorization"

\end_inset

.
 Interprocessor migration has traditionally been forbidden in real-time
 systems for the following reasons: 
\end_layout

\begin_layout Standard
 In many systems, the cost associated with each migration  i.e.
 , the cost of transferring a jobs context from one processor to another
  can be prohibitive.
 
\end_layout

\begin_layout Standard
 Until recently, traditional real-time scheduling theory lacked the techniques,
 tools, and results to permit a detailed analysis of systems that allow
 migration.
 Hence, partitioning has been the preferred approach due largely to the
 non-existence of viable alternative approaches.
 Recent developments in computer architecture, including single-chip multiproces
sors and very fast interconnection networks over small areas, have resulted
 in the first of these concerns becoming less of an issue.
 Thus, system designers need no longer rule out interprocessor migration
 solely due to implementation considerations, especially in tightly-coupled
 systems.
 (However, it may still be desirable to strict overhead in order to reduce
 runtime overhead.) In addition, results of recent experiments demonstrate
 that scheduling algorithms that allow migration are competitive in terms
 of schedulability with those that do not migrate, even after incorporating
 migration overheads [26].
 This is due to the fact that systems exist that can be successfully scheduled
 only if interprocessor 5 migration is allowed (refer to Lemmas 3 and 4
 in Section 3)
\end_layout

\begin_layout Standard
Migration addresses points 5 and 6 of the protocol : A thread that is spinning
 for a lock already held on another processor must be able to give way to
 the preempted holder locally.
\end_layout

\begin_layout Subsection
Schedulability Analysis
\end_layout

\begin_layout Subsection
Runtime Overhead in SMP computers
\end_layout

\begin_layout Subsection
Limitations
\end_layout

\begin_layout Subsection
Project Goals Revisited and Project Requirements
\end_layout

\begin_layout Section
MrsP : Design and Implementation
\end_layout

\begin_layout Subsection
Linux real-time scheduling algorithm
\end_layout

\begin_layout Subsubsection
Kernel Preemption
\end_layout

\begin_layout Itemize
Linux, prior to the 2.5 Linux Kernel, was a non-preemptive kernel.
 That means that whenever a thread was running in 
\series bold
kernel context
\series default
 (for instance a user application making a system call) that thread would
 not be preempted unless it volunteered to schedule (calls yield() function)
 -> basic Non Preemptive Protocol.
 The 2.6 version of the Linux Kernel introduces preemption and protects critical
 section through the use of spin-locks e.g.
 busy-waiting locks 
\begin_inset CommandInset citation
LatexCommand cite
key "rostedt2007internals"

\end_inset

.
 This was a major improvement however it still allowed lower threads blocking
 higher threads requesting access to the same shared resource or not.
 It makes sense for a spinlock to be fully non-preemptible for the following
 reasons: 
\end_layout

\begin_layout Itemize
Busy-waiting blocks a whole processor, we want to access and leave the critical
 section rapidly.
 
\end_layout

\begin_layout Itemize
Other tasks might be spinning on different processors for the same lock
\end_layout

\begin_layout Itemize
Interrupt kernel threads [
\series bold
Define
\series default
] are given priority over all other tasks, they can spin on the lock held
 by the preempted task and thus create a deadlock.
\end_layout

\begin_layout Standard
However spinlocks can create large non-deterministic latencies and that
 is conflicting with the requirements of an RTOS.
\end_layout

\begin_layout Standard
To address that issue the RT patch converts most spinlocks into a mutex
 
\begin_inset CommandInset citation
LatexCommand cite
key "rostedt2007internals"

\end_inset

, this has the effect to enable preemption in the critical sections as a
 task trying to lock an already held mutex will be suspended (deadlock avoided).
\end_layout

\begin_layout Subsubsection
Priority Inheritance Implementation
\end_layout

\begin_layout Standard
Priority inversion, e.g.
 lower tasks blocking higher ones is inherent to scheduling and can not
 be avoided, however unbounded priority inversion must be prevented.
 The RT patch chooses priority inheritance to address this issue.
\end_layout

\begin_layout Standard
The implementation of a PI mutex introduces a new concept, the priority
 inheritance chain described in 
\begin_inset CommandInset citation
LatexCommand cite
key "rostedt_rt_mutex"

\end_inset

.
\end_layout

\begin_layout Standard
The PI chain is an ordered series of locks and processes that cause tasks
 to inherit priorities from a higher process that is blocked on one of its
 locks.
 Different chains may be merged as several tasks can wait on a lock, but
 a chain would never diverge, since a task can't be blocked on more than
 one lock at a time.
 
\end_layout

\begin_layout Subsubsection
High Resolution Timers
\end_layout

\begin_layout Subsubsection
Comparison with other RTOSes
\end_layout

\begin_layout Subsubsection
Implementation in Linux Kernel
\end_layout

\begin_layout Subsubsection
The Linux real-time scheduling algorithm
\end_layout

\begin_layout Subsubsection
Key Data Structures
\end_layout

\begin_layout Paragraph
task_struct
\end_layout

\begin_layout Standard
This data structure represents a task in the system.
 It contains useful information for the scheduler such as the real-time
 priority of a task, its current state (running, sleeping, etc..) and the
 policy under which it is being scheduled.
 
\end_layout

\begin_layout Paragraph
runqueue
\end_layout

\begin_layout Standard
There is two runqueue per processor, one of which is listing the active
 tasks and the other the expired tasks.
 A runqueue is a linked list composed of 140 nodes corresponding to each
 priority level.
 Each node is itself a linked list referencing the tasks of the same priority.
\end_layout

\begin_layout Paragraph
futex
\end_layout

\begin_layout Standard
A futex, 
\begin_inset Quotes eld
\end_inset

Fast userspace mutex
\begin_inset Quotes erd
\end_inset

, is a locking primitive that is used to build more complex locking structures.
 It is composed of a 32 bits integer and a waitqueue referencing the tasks
 waiting to acquire the lock.
 It is used in mutexes when there is contention over a lock (a task is waiting
 for a lock already hold).
\end_layout

\begin_layout Paragraph
rt_mutex
\end_layout

\begin_layout Standard
Also called Priority inheritance futex, like with futexes, the waiting task
 is added to a waitqueue.
 If its priority is higher than the holder's, it rises the holder's priority
 to its own priority.
 The priority inheritance is dynamic in the sense that, if the holder is
 itself waiting on a second futex, its temporarily enhanced priority will
 diffuse to the holder of the second futex.
 As soon as a task unlocks a futex its enhanced priority is set back to
 its initial one.
\end_layout

\begin_layout Subsubsection
Real-time scheduler
\end_layout

\begin_layout Standard
root domains
\end_layout

\begin_layout Standard
Pull and Push algorithms
\end_layout

\begin_layout Standard
[INCLUDE CHART]
\end_layout

\begin_layout Subsubsection
Priority Management in kernel
\end_layout

\begin_layout Subsection
Requirements of MrsP
\end_layout

\begin_layout Enumerate
Be able to assign one priority per processor to spinlocks
\end_layout

\begin_layout Enumerate
Make waiters spin and be able to get preempted only by holder
\end_layout

\begin_layout Enumerate
Make waiters add their affinities to holder
\end_layout

\begin_layout Enumerate
FIFO Spinlock
\end_layout

\begin_layout Subsection
FIFO Spinlock
\end_layout

\begin_layout Standard
In multithreading, spinlocks are rarely used, most applications favor the
 more sophisticated solution of mutexes.
 However with sophistication comes complexity, and complexity in computing
 often means slower response times.
 At kernel level, performance is crucial and areas are often protected with
 very short busy-waiting locks.
 Typically the spinlock is implemented as single variable acting as boolean
 indicating whether the resource is currently being used, tasks enter a
 loop and check continuously its value.
 MrsP requires busy-waiting, but not only, it also requires that a FIFO
 access to the lock is respected.
 The Pthread implementation for instance doesn't provide such a facility,
 resulting in threads competing for the lock.
 The three others requirements for MrsP are affinity inheritance, priority
 ceiling and the ability to assign one priority per processor to each lock.
 The following sections will give the details of a custom FIFO spinlock
 implemented to fulfill the above requirements.
\end_layout

\begin_layout Subsubsection
FIFO Spinlock basic algorithm
\end_layout

\begin_layout Standard
Our implementation is inspired from 
\begin_inset Quotes eld
\end_inset

Tickets Spinlocks
\begin_inset Quotes erd
\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "Piggin_ticket_spin"

\end_inset

 and the Lamport Bakery Algorithm.
 Below 
\series bold
[EXPLAIN]
\series default
 is a pseudo-code describing the algorithm.
\end_layout

\begin_layout Standard
\begin_inset listings
lstparams "basicstyle={\ttfamily},language=C"
inline false
status open

\begin_layout Plain Layout

LOCK {
\end_layout

\begin_layout Plain Layout

owner;
\end_layout

\begin_layout Plain Layout

next_ticket;
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

FIFO_Spin_Lock(LOCK L){
\end_layout

\begin_layout Plain Layout

 Atomic{
\end_layout

\begin_layout Plain Layout

 Local Ticket = L.next_ticket;
\end_layout

\begin_layout Plain Layout

 increment L.next_ticket;
\end_layout

\begin_layout Plain Layout

 }
\end_layout

\begin_layout Plain Layout

 WHILE Ticket != L.owner
\end_layout

\begin_layout Plain Layout

	Spin
\end_layout

\begin_layout Plain Layout

 ENDWHILE
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

FIFO_Spin_Unlock(LOCK L){
\end_layout

\begin_layout Plain Layout

 increment L.owner
\end_layout

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
The lock variables are initialized to zero at the beginning.
 The task calling FIFO_Spin_Lock starts by atomically getting a ticket number
 and increasing it by one.
 The task then spins in a busy loop waiting for its ticket number to be
 equal to the owner variable.
 The unlocking is done by a simple (atomic?) increase of the owner variable.
 
\end_layout

\begin_layout Standard
The 
\family typewriter
owner
\family default
 and 
\family typewriter
next_ticket
\family default
 are defined as unsigned 1 byte variables in our implementation which means
 there can be up to 255 tasks spinning on the same lock.
 We can notice that code above always increments the variable and never
 decrease them, which can lead to ask 
\begin_inset Quotes eld
\end_inset

How many accesses/tickets can a 1 byte variable provide
\begin_inset Quotes erd
\end_inset

.
 The algorithm takes advantage of the 
\family typewriter
\shape italic
wrapping
\family default
\shape default
 property of unsigned variables which resets the variable to zero in the
 case of an overflow.
 FIFO spinlocks therefore support an infinite number of accesses.
 
\end_layout

\begin_layout Subsubsection
FIFO Spinlock structure
\end_layout

\begin_layout Standard
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

struct fifo_spinlock_chart { 
\end_layout

\begin_layout Plain Layout

volatile pid_t  taskid; 
\end_layout

\begin_layout Plain Layout

volatile unsigned char owner; 
\end_layout

\begin_layout Plain Layout

volatile unsigned char next; 
\end_layout

\begin_layout Plain Layout

volatile unsigned char prio; 
\end_layout

\begin_layout Plain Layout

volatile unsigned char task_prio; 
\end_layout

\begin_layout Plain Layout

cpu_set_t saved_cpumask;
\end_layout

\begin_layout Plain Layout

} ;
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
taskid : This variable stores the task id of the task currently holding
 the lock (defaults to -1).
\end_layout

\begin_layout Itemize
owner : This variable keeps track of the ticket owner.
\end_layout

\begin_layout Itemize
next : This variable keeps track of the waiters to allow a FIFO access.
\end_layout

\begin_layout Itemize
prio : This variable is the priority ceiling of the lock.
\end_layout

\begin_layout Itemize
task_prio : This variable saves the priority the task had before attempting
 to take the lock.
\end_layout

\begin_layout Itemize
saved_cpumask : This variable saves the cpu affinities the task had before
 attempting to take the lock.
\end_layout

\begin_layout Paragraph
Priority ceiling
\end_layout

\begin_layout Standard
While POSIX Pthread mutexes specify and implement priority ceiling, Pthread
 spinlocks are kept very simple and do not benefit of such feature, because
 their rationale is performance and their use cases make them a rarely used
 feature of multithreading.
\end_layout

\begin_layout Paragraph
Affinity inheritance
\end_layout

\begin_layout Standard
MrsP requires waiting tasks to add the current cpu they are spinning on
 to the list of cpu affinities of the holder in case it gets preempted.
 This can be defined as 
\shape italic
affinity inheritance
\shape default
.
 The mechanism is very similar to the mechanism priority inheritance uses.
 When a task is waiting on a contended spinlock, it adds the cpu it is currently
 executing on to the holding task.
 This way in case of a forced migration e.g due to preemption, the holder
 task can migrate to processor where the task is currently waiting on the
 spinlock and preempt it.
 
\end_layout

\begin_layout Paragraph
Priority per processor
\end_layout

\begin_layout Standard
MrsP requires to have one priority per processor in case a task is preempted
 and migrated to another cpu.
 This is further described in TODO
\end_layout

\begin_layout Subsubsection
FIFO Spinlock MrsP Algorithm
\end_layout

\begin_layout Standard

\family typewriter
\begin_inset listings
lstparams "basicstyle={\normalsize\ttfamily},language=C"
inline false
status open

\begin_layout Plain Layout

LOCK {
\end_layout

\begin_layout Plain Layout

  owner;
\end_layout

\begin_layout Plain Layout

  next_ticket;
\end_layout

\begin_layout Plain Layout

  taskid;
\end_layout

\begin_layout Plain Layout

  prio_per_cpu;
\end_layout

\begin_layout Plain Layout

  save_task_prio;
\end_layout

\begin_layout Plain Layout

  save_task_affinity;
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

FIFO_Spin_Lock(LOCK L){
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

 #Declare local variables
\end_layout

\begin_layout Plain Layout

 Local copy_priority, copy_affinity
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

 copy_priority = Current Task.Priority
\end_layout

\begin_layout Plain Layout

 copy_affinity = Current Task.Affinity
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

 #Priority ceiling
\end_layout

\begin_layout Plain Layout

 Task.Prio_Per_CPU = L.prio_per_cpu
\end_layout

\begin_layout Plain Layout

 
\end_layout

\begin_layout Plain Layout

 Atomic{
\end_layout

\begin_layout Plain Layout

 Local Ticket = L.next_ticket;
\end_layout

\begin_layout Plain Layout

 increment L.next_ticket;
\end_layout

\begin_layout Plain Layout

 }
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

 #Affinity Inheritance to holder
\end_layout

\begin_layout Plain Layout

 IF L.taskid != NULL
\end_layout

\begin_layout Plain Layout

    ADD_Current_CPU(Task(L.taskid));
\end_layout

\begin_layout Plain Layout

 ENDIF
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

 WHILE Ticket != L.owner
\end_layout

\begin_layout Plain Layout

	Spin
\end_layout

\begin_layout Plain Layout

 ENDWHILE
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

 L.taskid = Current Task.ID
\end_layout

\begin_layout Plain Layout

 L.save_affinity = copy_affinity;
\end_layout

\begin_layout Plain Layout

 L.save_priority = copy_priority;
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

FIFO_Spin_Unlock(LOCK L){
\end_layout

\begin_layout Plain Layout

 L.taskid = undef
\end_layout

\begin_layout Plain Layout

 Task.Affinities = L.save_affinity
\end_layout

\begin_layout Plain Layout

 Task.Prio = L.save_priority
\end_layout

\begin_layout Plain Layout

 increment L.owner
\end_layout

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Implementation of MrsP 
\end_layout

\begin_layout Subsubsection
System calls
\end_layout

\begin_layout Standard
A system call (also called kernel call) is a request to a service typically
 made from userspace.
 The service needed is usually only accessible by the kernel because of
 its possible misuse that could damage the system integrity.
 System calls act as an Application Programming Interface for the kernel
 functions and enable to abstract hardware in a safe fashion from the user.
 As stated in the book Linux Kernel Development 
\begin_inset CommandInset citation
LatexCommand cite
key "love2010linux"

\end_inset

 : 
\shape italic
if tasks were free to access system and hardware resources without the kernel's
 knowledge, it would be nearly impossible to implement multitasking and
 virtual memory, and certainly impossible to do so with stability and security.
\end_layout

\begin_layout Paragraph
System call handler
\end_layout

\begin_layout Paragraph
System call overhead
\end_layout

\begin_layout Subsubsection
Modifications to the Linux Kernel
\end_layout

\begin_layout Standard
We have added a variable in the task_struct definition that can hold one
 priority per processor.
\end_layout

\begin_layout Standard
We have added a bitmask in the task_struct definition that holds the inherited
 processor affinities.
 Those are added to the task holding the lock and removed when it releases
 the lock.
\end_layout

\begin_layout Standard
We have added a boolean variable to make a task scheduled under our algorithm.
 TODO to be modified for a new scheduling policy (SCHED_MRSP).
\end_layout

\begin_layout Standard
A call to sys_futex with SCHED_MRSP makes the thread spin at local ceiling
 for the rt-mutex.
\end_layout

\begin_layout Standard
The task is checked when being migrated between two cpus, if a task is spinning
 on that cpu, it raises its own priority to task_on_other_cpu +1 so that
 it can preempt it.
\end_layout

\begin_layout Standard
We take advantage of the previously implemented PI-futexes.
\end_layout

\begin_layout Paragraph
Task migration
\end_layout

\begin_layout Standard
When the task is being migrated by the scheduler, we detect it and modify
 it before it gets added to the target cpu.
\end_layout

\begin_layout Subsubsection
MRSP API
\end_layout

\begin_layout Standard
A system call sys_set_smp_prio allows to set one priority per task.
\end_layout

\begin_layout Standard
Task spinning giving up its share -> cooperative scheduling ?
\end_layout

\begin_layout Subsection
Semi-partitioned systems considerations
\end_layout

\begin_layout Subsection
Globally partitioned systems considerations
\end_layout

\begin_layout Subsection
Limitations
\end_layout

\begin_layout Section
Results and evaluation
\end_layout

\begin_layout Subsection
Tools
\end_layout

\begin_layout Subsubsection
QEMU
\end_layout

\begin_layout Subsubsection
Kernelshark and trace-cmd
\end_layout

\begin_layout Subsubsection
ftrace & profiling
\end_layout

\begin_layout Subsection
Hardware
\end_layout

\begin_layout Subsection
Test Cases
\end_layout

\begin_layout Section
Conclusion and Further Work
\end_layout

\begin_layout Subsection
Project Review
\end_layout

\begin_layout Subsection
Overview of the project
\end_layout

\begin_layout Subsection
Strengths
\end_layout

\begin_layout Subsection
Weaknesses
\end_layout

\begin_layout Subsection
Limitations
\end_layout

\begin_layout Subsection
Recommendation for further research
\end_layout

\begin_layout Standard
Given the plethora of available resource sharing protocols.
\end_layout

\begin_layout Standard
Each resource sharing protocol seems to suit a particular type of programming
 (slow or quick resources, intensive or sparse sharing, number of tasks,
 etc..).
 An approach that might be considered is to build a framework that automatically
 selects the best resource sharing algorithm for a given program.
 Why not even think about dynamically changing a policy during runtime,
 going to the realm of strategy (schedulability) and tactics (different
 protocols).
\end_layout

\begin_layout Subsection
Final Words
\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "cite"
options "plain"

\end_inset


\end_layout

\end_body
\end_document
