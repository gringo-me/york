#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref true
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder false
\pdf_colorlinks false
\pdf_backref false
\pdf_pdfusetitle true
\papersize default
\use_geometry false
\use_amsmath 1
\use_esint 1
\use_mhchem 1
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 1
\backgroundcolor #ffffff
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 4
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title

\family typewriter
\size huge
A Schedulability Compatible Multiprocessor Resource Sharing Protocol
\end_layout

\begin_layout Standard
\align center

\size largest
Msc Software Engineering Dissertation
\end_layout

\begin_layout Standard
\align center

\size largest
Y0017846
\end_layout

\begin_layout Standard
\align center

\shape smallcaps
\size largest
University of York
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vspace*{
\backslash
fill}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Abstract
Multiprocessor real-time resource control algorithms are currently an active
 research topic as more and more real-time systems become multicore.
\end_layout

\begin_layout Abstract
This project intends to contribute to the field of multiprocessor resource
 sharing protocols in real-time systems.
 Multiprocessor architectures have become mainstream, used in small embedded
 devices as well as enterprise servers.
 Multiple processing units architectures offer increasing computational
 capacity performance that need to be efficiently employed.
 While we can expect massively multi-core processors chips to be available
 soon, research in the real-time systems has been mainly designed for single
 processors.
 The widespread use of multicore architectures is challenging the real-time
 systems area for a protocol that could make a consensus and presenting
 features that are at least as good as the single processor protocols.
 The purpose of a lock-based multiprocessor resource sharing protocol implementa
tion in an operating system as popular as Linux is a step forward to catch
 up on processor manufacturers.
\end_layout

\begin_layout Abstract
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Standard

\size larger
Ideas
\end_layout

\begin_layout Standard
Difference between scheduling and resource sharing
\end_layout

\begin_layout Standard
Chart illustrating the protocol (state machine diagram)
\end_layout

\begin_layout Standard
Implement prototype in C as a working stand alone state machine (without
 kernel complexities)
\end_layout

\begin_layout Standard
Importance of metrics
\end_layout

\begin_layout Standard
Implement protocol with kernel
\end_layout

\begin_layout Standard

\series bold
Investigate : How does Linux do SMP real-time scheduling ?
\end_layout

\begin_layout Standard

\series bold
Investigate : How to allow threads to have a priority per processor ?
\end_layout

\begin_layout Standard
How do we assess/certify the priority of threads ?
\end_layout

\begin_layout Standard
How can the Linux Kernel be modified to allow a priority per processor ?
 
\end_layout

\begin_layout Enumerate
Modify task_struct in sched.h and add a priority per processor variable
\end_layout

\begin_layout Enumerate
Modify migrate_thread to set the new priority on that processor
\end_layout

\begin_layout Standard
What is the estimated time ?
\end_layout

\begin_layout Standard
Is there an overhead associated to a priority per processor ?
\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
This section will briefly describe the reasons for undertaking this project.
 It will introduce the technical requirements involved, as well as present
 the development workflow and finally the ethics used to complete it.
\end_layout

\begin_layout Subsection
Motivation
\end_layout

\begin_layout Standard
The Real-Time System Group at York have recently proposed a new multiprocessor
 resource sharing algorithm
\begin_inset CommandInset citation
LatexCommand cite
key "burns2013schedulability"

\end_inset

 based on a well known single processor resource sharing protocol.
 This report provides an implementation in a Linux Real-Time kernel.
 
\end_layout

\begin_layout Subsection
Project Goals
\end_layout

\begin_layout Subsection
Deliverables
\end_layout

\begin_layout Subsection
Ethics in the project
\end_layout

\begin_layout Subsection
Report structure
\end_layout

\begin_layout Section
Background and Literature Review
\end_layout

\begin_layout Subsection
Real-time systems
\end_layout

\begin_layout Standard
In the real-time paradigm besides of the usually expected functional correctness
 of a system, the timing e.g.
 the time needed to process an input must comply with a deadline.
 Young
\begin_inset CommandInset citation
LatexCommand cite
key "young1982real"

\end_inset

 gives the following definition : 
\end_layout

\begin_layout Quote

\shape italic
Any information processing activity or system which has to respond to externally
 generated input stimuli within a finite and specified period.
\end_layout

\begin_layout Standard
A real-time system is ordinarily composed of concurrent tasks sharing common
 resources.
 Tasks execute a sequence of operations in parallel, they have a deadline
 representing the maximum acceptable response time.
 Tasks can be classified as periodic meaning they are triggered at regular
 intervals or aperiodic meaning they can be triggered at any time.
 A subset of aperiodic tasks are sporadic tasks, these can be triggered
 at any time with the condition that they respect a minimum time between
 each release.
\end_layout

\begin_layout Standard
Concurrent programming has been studied and developed a long time before
 the apparition of multiprocessors architectures.
 It might seem odd to have concurrent execution of tasks on single processor
 systems and indeed operating systems 
\shape italic
give the impression 
\shape default
of concurrency by allocating short execution time to each task according
 to a policy implemented in the task scheduler.
 In real time systems, the scheduling is performed using task priorities.
\end_layout

\begin_layout Standard
We make the difference between 
\shape italic
hard, soft 
\shape default
and
\shape italic
 firm
\shape default
 real-time systems.
 Hard real-time systems put a strict constraint on respecting the deadline,
 they are usually used in industries in which response time is critical
 and where a failure to execute within the deadline equals to a system failure.
 On the other hand, soft real-time systems consider the deadline as a recommenda
tion therefore missing a deadline is not a serious error however it does
 decrease the value of the expected output.
 In firm real-time systems, missing a deadline is not a system failure although
 the output of a task is discarded by the system.
\end_layout

\begin_layout Subsection
Real-time multiprocessor scheduling
\end_layout

\begin_layout Standard
Operating systems implement schedulers to efficiently allocate processor
 resource time to tasks.
 Schedulers are inherent to multitasking.
\end_layout

\begin_layout Standard
Real-time multiprocessor scheduling protocols are divided among three classes
 : 
\shape italic
partitioned scheduling, semi-partitioned scheduling 
\shape default
and
\shape italic
 global scheduling
\end_layout

\begin_layout Standard
Each above class can be implemented with either 
\shape italic
fixed-priority (FP) 
\shape default
or
\shape italic
 earliest-deadline-first
\shape default
 (EDF) policies.
\end_layout

\begin_layout Subsubsection
Scheduling Policies
\end_layout

\begin_layout Subsubsection
Scheduling protocols
\end_layout

\begin_layout Paragraph
Global scheduling protocols
\end_layout

\begin_layout Standard
In global scheduling, a single queue of tasks is dispatched among the processors.
 Global scheduling protocols traditionally have an EDF policy.
\end_layout

\begin_layout Paragraph
Partitioned scheduling protocols
\end_layout

\begin_layout Standard
In partitioned scheduling each task is statically assigned a processor e.g.
 migrations between processors are not allowed.
 Each processor is scheduled independently.
 In other words partitioning reduces the multiprocessor scheduling problem
 to a set of uniprocessor
\begin_inset CommandInset citation
LatexCommand cite
key "carpenter2004categorization"

\end_inset

.
 This form of scheduling is the most used because it reuses well-known concepts
 of uniprocessor scheduling.
\end_layout

\begin_layout Paragraph
Semi-partitioned protocols
\end_layout

\begin_layout Standard
Semi-partitioned protocols are a compromise between global and partitioned
 protocols.
 Processors are grouped into subsets.
 A task is statically assigned to a set of processors.
 Each subset is then scheduled globally.
 
\end_layout

\begin_layout Subsection
Problems and Concepts in Real-time Resource Sharing Protocols 
\end_layout

\begin_layout Standard

\series bold
PROBLEMS (Caused by mutual exclusion -> solved by resource sharing protocols)
\end_layout

\begin_layout Standard

\series bold
The major problems these protocols intend to solve are : 
\end_layout

\begin_layout Subparagraph

\series bold
Deadlocks (nested resources)
\end_layout

\begin_layout Standard
Deadlock is a task and resource configuration where two tasks or more are
 holding a resource and each is respectively waiting on the other to release
 its resource.
 The result is that each task waits forever and cannot continue its execution.
 Resource sharing protocols will sometimes try to prevent that situation,
 however it is often the user's duty to ensure it doesn't happen by following
 good programming practices.
 Often deadlock situations are created when locks are not taken in the same
 order.
\end_layout

\begin_layout Subparagraph

\series bold
Resource starvation
\end_layout

\begin_layout Standard

\series bold
[Round-Robin ?]
\end_layout

\begin_layout Standard
In a system where tasks are competing for resources access, resource starvation
 occurs when a task's request to access to a resource is never satisfied
 by the scheduler.
 Therefore that task cannot make progress and blocks forever.
 Resource starvation appears when for instance the scheduler schedules the
 execution of tasks without ensuring fairness between threads.
 
\end_layout

\begin_layout Standard
The readers-writers problem illustrates well that situation, the terms of
 the problem are as follows : 
\end_layout

\begin_layout Itemize
There is a resource R which many writer tasks are allowed to use, as well
 as many reader tasks.
 
\end_layout

\begin_layout Itemize
Readers and writers are not allowed access at the same time.
 
\end_layout

\begin_layout Itemize
Two or more readers can access R at the same time.
\end_layout

\begin_layout Itemize
Writers can only access R individually
\end_layout

\begin_deeper
\begin_layout Standard
While writers requesting access have to do it by turn and wait for each
 other to release the resource, readers don't have to wait.
 Naive attempts to solve this problem such as letting readers access the
 resource without taking into account waiting writers can result in resource
 starvation for writers.
\end_layout

\end_deeper
\begin_layout Subparagraph

\series bold
Unbounded Priority Inversion -> Priority inheritance meant to solve this
\end_layout

\begin_layout Standard

\series bold
Mars Path Finder famous priority inversion
\end_layout

\begin_layout Standard
Priority inversion is a situation where a higher priority task gets preempted
 or has its execution delayed by a lower priority task.
 For instance given H, M, L respectively tasks of high, medium and low priority,
 consider : L accesses a resource R, H is released and wants to access R,
 it has to wait until L is finished with it (Priority Inversion).
 While H is waiting, M gets released and preempts L, H has now to wait for
 M + L execution time, moreover M could itself be preempted by a second
 task M2 slightly higher than M but lower than H (Unbounded Priority Inversion)
 .
 Priority inversion is normal and unavoidable in scheduling because predicting
 when two tasks of different priorities will access the same mutually exclusive
 area or resource is hard [EXAMPLE] or impossible.
 Unbounded priority inversion can and must be avoided.
 Priority inheritance is one method to minimize the effects of priority
 inversion by propagating the highest priority task requesting access to
 a resource to lower priority tasks requesting access to that same resource,
 rendering them non-preemptable by medium priority tasks.
\end_layout

\begin_layout Standard

\series bold
Deadline Inversion
\end_layout

\begin_layout Standard

\series bold
A task with short deadline is blocked by a task with longer deadline for
 an unbounded interval of time.
 
\end_layout

\begin_layout Standard
==================
\end_layout

\begin_layout Standard

\series bold
Concepts
\end_layout

\begin_layout Subparagraph

\series bold
Local Or Global Resources
\end_layout

\begin_layout Standard
Some scheduling protocols classify resources as being global or local.
 Global resources can be accessed by all the tasks while local resources
 can only be accessed on specific processors to whom they are assigned.
 
\end_layout

\begin_layout Standard
Example of resources :
\end_layout

\begin_layout Itemize
Variables in memory (RAM, hard-disk, processor cache )
\end_layout

\begin_layout Itemize
Hardware device or appliance (fax, printer) 
\end_layout

\begin_layout Itemize
Connection channel 
\end_layout

\begin_layout Itemize
Database
\end_layout

\begin_layout Subparagraph

\series bold
Suspend based or Spin based waiting
\end_layout

\begin_layout Standard
Scheduling protocols can be suspend-based or spin-based when wanting to
 acquire a resource.
 Suspend-based means that task relinquish the processor and become idle
 until the resource becomes free.
 Spin-based means that task continue their execution, continuously checking
 if the resource has become free.
 Suspend-based is the most encountered model in the userspace however spinning
 is widely used at kernel level.
 The typical suspend based structure is the mutex, the typical spin based
 structure is the spinlock.
\end_layout

\begin_layout Subparagraph

\series bold
Schedulability Analysis (Response Time Analysis)
\end_layout

\begin_layout Standard
Real-time systems have response time and timings that must be guaranteed,
 schedulability analysis is a mathematical method designed to prove the
 scheduler correctness for a configuration of tasks and resources given
 their priority and deadlines.
 Such configuration can be proven to be schedulable, which means that all
 tasks in that configuration are guaranteeed to meet their deadlines.
 While an analysis can be sufficient to prove a set of task and resources
 to be schedulable, not all configuration of tasks and resources can be
 proved.
 Schedulability analysis can be applied to fixed-priority (FP) or earliest-deadl
ine-first (EDF) systems.
\end_layout

\begin_layout Standard

\series bold
Transitive blocking
\series default
 
\end_layout

\begin_layout Standard
By not-directly involved semaphores which are accessed in a nested form
 by blocking jobs.
 Transitive blocking is said to occur if a job J is blocked by J1 which,
 in turn, is blocked by another job J2 
\end_layout

\begin_layout Standard

\series bold
Fixed Priority (FP)
\end_layout

\begin_layout Standard
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard

\series bold
Earliest Deadline First (EDF)
\end_layout

\begin_layout Standard
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard

\series bold
The performance parameter are:
\end_layout

\begin_layout Enumerate

\series bold
Contention of High priority threads
\end_layout

\begin_layout Standard
Mutual exclusion to a critical section may be implemented on a uniprocessor
 (UP) system by simply preventing the thread that accesses the section from
 being preempted.
 On a symmetric multiprocessor (SMP) system, disabling pre- emption is not
 enough.
 A thread on another CPU might access the critical section.
 [Internal RT paper]
\end_layout

\begin_layout Standard
____________________
\end_layout

\begin_layout Standard
Spin_locks are relatively fast.
 The idea behind a spin_lock is to protect critical sections that are very
 short.
 A spin_lock is considered fast compared to suspend-based locks because
 it avoids the overhead of a re-schedule.
 [Internal RT papers]
\end_layout

\begin_layout Standard
____________________
\end_layout

\begin_layout Standard
If the time to run the code in a critical section is shorter than the time
 of a context switch, it is reasonable to use a spin_lock, and on contention,
 spin in a busy loop, while waiting for a thread on another CPU to release
 the spin_lock.
 [Internals RT]
\end_layout

\begin_layout Standard
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Subsection

\series bold
Real-time Resource Sharing Uniprocessor Protocols
\end_layout

\begin_layout Subsubsection
Non Preemptive Protocol
\end_layout

\begin_layout Subparagraph

\series bold
Description
\end_layout

\begin_layout Standard
The Non Preemptive Protocol is a simple approach to resource sharing.
 It can be described as follows : when a task enters a mutually exclusive
 area it can't be preempted by any other task.
 
\end_layout

\begin_layout Standard

\series bold
Advantages
\end_layout

\begin_layout Itemize
The implementation of the non-preemptive protocol is very simple.
 
\end_layout

\begin_layout Itemize
Good when access to resources are (very) short.
\end_layout

\begin_layout Subparagraph

\series bold
Limitations
\end_layout

\begin_layout Itemize
This protocol allows low priority tasks to block higher priority tasks that
 are not even requiring access to shared resources which is a form of priority
 inversion.
 
\end_layout

\begin_layout Itemize
Unbounded priority inversion can occur since a task can stay in a mutually
 exclusive area remain in it for a possibly unpredictable amount of time
 (for instance it can be waiting for network data or access large data).
\end_layout

\begin_layout Subsubsection
Priority Inheritance Protocol
\end_layout

\begin_layout Standard
In the Non-Preemptive Protocol no measure is taken to prevent unbounded
 priority inversion.
 The Priority Inheritance Protocol intends to correct that by introducing
 priority inheritance.
\end_layout

\begin_layout Subparagraph
Description
\end_layout

\begin_layout Itemize
Tasks have an original priority.
\end_layout

\begin_layout Itemize
Propagation of priority (e.g priority inheritance) : when a lower priority
 task C holds a resource needed by a higher priority task A, C inherits
 the priority of A.
\end_layout

\begin_layout Itemize
Transitive propagation of inheritance : If task C blocks task B which is
 itself blocking task A then C inherits the priority of A.
\end_layout

\begin_layout Itemize
Tasks are set back to original priority upon leaving a critical section.
\end_layout

\begin_layout Subparagraph
Advantages
\end_layout

\begin_layout Itemize
Bounded Priority Inversion
\end_layout

\begin_layout Subparagraph
Limitations
\end_layout

\begin_layout Itemize
Does not prevent deadlocks when locks are not taken in the same order (see
 Figure [NUMBER])
\end_layout

\begin_layout Itemize
Does not prevent chained blocking : High task needs resources R1 then R2
 which are held by two different lower tasks, the higher task has to wait
 for both lower priority tasks.
\end_layout

\begin_layout Standard
Two types of blocking are distinguished in this protocol :
\end_layout

\begin_layout Enumerate
Direct blocking : a lower task holding a resource blocks a higher task requestin
g access to that resource.
\end_layout

\begin_layout Enumerate
Priority Inheritance blocking : a medium task is blocked by a lower task
 that temporarily inherited a higher priority.
\end_layout

\begin_layout Subsubsection
The Priority Ceiling Protocol
\end_layout

\begin_layout Standard
The Priority Inheritance protocol solves the problem of unbounded priority
 inversion, however deadlocks and chained blocking are no prevented.
 The intent of the Priority Ceiling Protocol is to mitigate the limitations
 of the Priority Inheritance Protocol.
\end_layout

\begin_layout Subparagraph
Description
\end_layout

\begin_layout Itemize
Each resource has a ceiling value defined as the maximum priority of all
 tasks that use it.
\end_layout

\begin_layout Itemize
A task is allowed to enter a critical section only if its priority is higher
 than all of resources ceilings held by other tasks
\end_layout

\begin_layout Subparagraph
Advantages
\end_layout

\begin_layout Itemize
Prevents deadlocks.
\end_layout

\begin_layout Itemize
Prevents transitive blocking.
\end_layout

\begin_layout Itemize
Prevents chained blocking.
\end_layout

\begin_layout Itemize
The maximum blocking delay for a task is bounded by the duration of the
 longest critical section among those of lower priority tasks.
\end_layout

\begin_layout Subparagraph
Limitations
\end_layout

\begin_layout Itemize
Introduces a new type of blocking : priority ceiling blocking [Explain]
\end_layout

\begin_layout Itemize
Increases the number of context switches (it is expensive to switch and
 load a different context)
\end_layout

\begin_layout Itemize
Implementation is complex
\end_layout

\begin_layout Subsubsection
Immediate Priority Ceiling Protocol
\end_layout

\begin_layout Standard
The Immediate Priority Ceiling Protocol is a simplified version of the Priority
 Ceiling Protocol.
 While keeping all the advantages of PCP, it aims to decrease the number
 of context switches.
\end_layout

\begin_layout Standard

\series bold
Description
\end_layout

\begin_layout Itemize
Each task has a default original priority.
\end_layout

\begin_layout Itemize
A task's priority is raised to the resource ceiling immediately upon ownership
 acquisition.
\end_layout

\begin_layout Subparagraph

\series bold
Advantages
\end_layout

\begin_layout Itemize
Same advantages as PCP
\end_layout

\begin_layout Itemize
Additional advantage of less context switches
\end_layout

\begin_layout Subparagraph

\series bold
Performance
\end_layout

\begin_layout Standard
Same worst case performance as the Priority Ceiling Protocol
\end_layout

\begin_layout Standard
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard

\series bold
Limitations
\end_layout

\begin_layout Standard
A higher number of tasks priority changes is traded for less context switches,
 in most computer and operating systems architecture this is beneficial.
\end_layout

\begin_layout Subsubsection
Stack Resource Policy
\end_layout

\begin_layout Standard
The Stack Resource Policy intends to reduce the number of context switches
 introduced by PCP by anticipating the execution order of tasks.
 Notably this protocol is equally suited for EDF and FP systems.
 It generalises the concept of task priority by defining a 
\shape italic
preemption level 
\shape default
corresponding to the task priority in FP systems and to the inversely proportion
al task deadline (the closer the deadline the higher the preemption level).
\end_layout

\begin_layout Standard
In this protocol, a task is not allowed to execute until the resources it
 needs are available.
 Traditionally in scheduling protocols, each task has a private stack where
 subroutines calls are pushed and popped to keep track of its current progress.
 On the SRP tasks can share their stack.
 Each resource is assigned a maximum ceiling (maximum priority of all tasks
 using it).
 
\end_layout

\begin_layout Subparagraph
Description
\end_layout

\begin_layout Itemize
Each task is assigned a fixed preemption level
\end_layout

\begin_layout Itemize
Each resource is assigned a preemption ceiling that corresponds to the maximum
 preemption level of all tasks using that resource
\end_layout

\begin_layout Itemize
A task is not allowed to run until its priority is highest among the tasks
 ready to run and its preemption level is higher than the system ceiling.
\end_layout

\begin_layout Subparagraph
Advantages
\end_layout

\begin_layout Itemize
Limits blocking to the beginning of the task
\end_layout

\begin_layout Itemize
Prevents deadlock
\end_layout

\begin_layout Standard

\series bold
Performance
\end_layout

\begin_layout Standard

\series bold
Limitations
\end_layout

\begin_layout Subsection
Real-time Resource Sharing Multiprocessor Protocols
\end_layout

\begin_layout Subsubsection
The Multiprocessor Priority Ceiling Protocol (MPCP)
\end_layout

\begin_layout Paragraph
Description
\end_layout

\begin_layout Standard
Rajkumar designed Multiprocessor Priority Ceiling Protocol (MPCP ) 
\series bold
[REF]
\series default
 that extends PCP (Priority Ceiling Protocol).
 Resources are regarded as local or global e.g.
 shared between tasks on different processors.
 Local resources locking is managed using PCP.
 However when acquiring a lock to a global resource, the holding task gets
 its priority raised to a value higher than all running tasks priorities
 in the system.
 If the resource is already held the requesting task is queued to a waiting
 list and its priority raised to the resource ceiling.
 As noted by 
\begin_inset CommandInset citation
LatexCommand cite
key "davis2011survey"

\end_inset

 while MPCP allows for lower tasks to execute while a global lock is held
 by a task on another processor, this can lead to a further priority inversion
 with a lower task executing taking first a local lock and then a global
 one.
 Even if the resource the higher task is waiting on is released it won't
 be able to execute.
\end_layout

\begin_layout Paragraph
Constraints
\end_layout

\begin_layout Standard
To prevent unbounded priority inversion, local to global and global to global
 nested locks are not allowed.
\end_layout

\begin_layout Paragraph
Performance
\end_layout

\begin_layout Subsubsection
The Multiprocessor Stack Resource Policy (MSRP)
\end_layout

\begin_layout Paragraph
Description
\end_layout

\begin_layout Standard
The Multiprocessor Stack Resource Policy (MRSP) is an extension proposed
 by [REF] of the uniprocessor Stack Resource Policy from [REF] (SRP).
 SRP is an EDF protocol.
 The deadline of each task represents a priority level.
 The earlier the deadline the higher the priority.
 Each resource is assigned a priority ceiling corresponding to the priority
 level of the higher task using that resource.
 A new M parameter is also introduced, M corresponds to the maximum of all
 the resources ceiling being used at instant T.
 Any task wanting to execute must have a priority higher than M.
\end_layout

\begin_layout Standard
SRP guarantees no blocking when a task is allowed to execute thus enabling
 stack sharing (each task execution is serialized - no interleaving).
\end_layout

\begin_layout Standard
Under MRSP as in MPCP resources are divided into local and global groups.
 Global resources have one ceiling per processor.
 A task on a processor is allowed to execute only if it has the processor
 ceiling priority which preserve the property of non-preemptability once
 a task starts executing.
\end_layout

\begin_layout Standard
Furthermore when a task is blocked on a global resource, it spins non-preemptive
ly to preserve the stack sharing property.
\end_layout

\begin_layout Standard
Tasks accessing nested local and global resources need to be allocated the
 same processor[CHECK].
 
\end_layout

\begin_layout Paragraph
Constraints
\end_layout

\begin_layout Paragraph
Performance
\end_layout

\begin_layout Paragraph
Limitations
\end_layout

\begin_layout Subsubsection
The Flexible Multiprocessor Locking Protocol (FMLP) 
\end_layout

\begin_layout Standard
FMLP requires the user to divide resources between long and short access
 times.
 Access is differentiated in function of the type of the resource : short
 resources benefit from busy-waiting (reduces context-switching), long resources
 are handled through suspend-waiting in a FIFO manner.
 A task holding a short resource is not allowed to require access to a long
 resource to avoid deadlock.
 
\end_layout

\begin_layout Paragraph
Description
\end_layout

\begin_layout Paragraph
Constraints
\end_layout

\begin_layout Paragraph
Performance
\end_layout

\begin_layout Standard
FMLP has better performance than MSRP.
 This advantage is at least partly due to the fact that FMLP removes the
 restriction on task allocation required by MSRP 
\begin_inset CommandInset citation
LatexCommand cite
key "davis2011survey"

\end_inset

.
 
\end_layout

\begin_layout Paragraph
Limitations
\end_layout

\begin_layout Subsubsection
Parallel PCP (P-PCP) 
\end_layout

\begin_layout Subsubsection
O(m) Locking Protocol (OMLP) 
\end_layout

\begin_layout Standard
OMLP makes use of a two-level priority queue scheme to allow access to a
 global resource.
 
\end_layout

\begin_layout Standard
Under partitioned scheduling, tasks requiring access to a global resource
 are first put on local priority queue and then in a global prioritized
 queue.
 The highest priority task on the local queue is selected to be put on the
 global queue and its priority is raised to the local ceiling (maximum priority
 being used on the processor) to make it locally non-preemptible, however
 the task might still be suspended if there is high contention on the global
 queue.
\end_layout

\begin_layout Standard
Under global scheduling, tasks requiring access to a 
\end_layout

\begin_layout Subsubsection
M-BWI 
\end_layout

\begin_layout Standard
Many other protocols exist
\end_layout

\begin_layout Subsection
Real-time multiprocessor operating systems
\end_layout

\begin_layout Subsubsection
Characteristics of SMP machines
\end_layout

\begin_layout Subsubsection
Processor Caches
\end_layout

\begin_layout Standard
A processor cache is a fast memory the processor uses to reduce time to
 access memory.
 The cache memory is smaller than the RAM, it is used to stores copies of
 frequently used locations in the RAM.
 Most processors have a two-level cache system L1 (fastest) and L2.
 A processor will typically always check the caches for the data used by
 a task before looking into the RAM.
 A cache miss occurs when the data is not available in any of the caches.
 A process is called 
\shape italic
cache-hot 
\shape default
when it has the requested data in one of the caches.
 Now we can see that the operating system task scheduler will always try
 to have as few cache misses as possible, therefore avoiding slower RAM
 lookups.
\end_layout

\begin_layout Subsubsection
Processor affinity
\end_layout

\begin_layout Standard
Processor affinity enables the pinning of a process or a thread to a processor
 or a set of processors, so that the process will only execute on the designated
 processor set.
 This is however on Linux only a hint to the scheduler and there is no guarantee
 that it will be respected.
 
\end_layout

\begin_layout Subsubsection
Cost of migration 
\end_layout

\begin_layout Standard
The cost of two migrations must be less than the interference of a higher
 priority thread.
 Also a migrating thread is likely to suffer from an execution time penalty
 as its local cache cannot be utilised.
 However, a preempted thread is also likely to have its data in cache overwritte
n by the time it executes again.
 
\end_layout

\begin_layout Subsection
Summary
\end_layout

\begin_layout Section
The Multiprocessor Resource Sharing Protocol
\end_layout

\begin_layout Subsection
Description
\end_layout

\begin_layout Standard
Here we present informally the protocol as it is described in details in
 
\begin_inset CommandInset citation
LatexCommand cite
key "burns2013schedulability"

\end_inset


\end_layout

\begin_layout Standard
We assume a fully partitioned system.
 That is, each thread can only execute on one processor.
 
\end_layout

\begin_layout Enumerate
All mutexes are assigned a set of ceiling priorities, one per processor
 (for those processors that have threads that use the mutex); for processor
 Pk the mutex's priority is the maximum priority of all threads allocated
 to Pk that use the mutex.
 
\end_layout

\begin_layout Enumerate
A lock request on any mutex results in the priority of the thread being
 immediately raised (ICPP) to the local ceiling for the mutex i.e the mutex's
 priority for the processor executing the thread.
\end_layout

\begin_layout Enumerate
Accesses to a mutex are dealt with in a FIFO order.
 
\end_layout

\begin_layout Enumerate
While waiting to gain access to the mutex, and while actually holding the
 mutex, the thread continues to be active and executes (possible spinning)
 with priority equal to the local ceiling of the mutex.
 
\end_layout

\begin_layout Enumerate
Any thread waiting to gain access to a mutex must be capable of undertaking
 the associated computation on behalf of any other waiting thread (SPEPP).
 
\end_layout

\begin_layout Enumerate
This cooperating thread must undertake the outstanding requests in the original
 FIFO order.
 
\end_layout

\begin_layout Subsection
A migration approach
\end_layout

\begin_layout Standard
While the protocol developed is intended for partitioned systems, thread
 migration between processors is common in SMP operating systems.
\end_layout

\begin_layout Standard
Migration-based classification 
\begin_inset CommandInset citation
LatexCommand cite
key "carpenter2004categorization"

\end_inset

.
 Interprocessor migration has traditionally been forbidden in real-time
 systems for the following reasons: 
\end_layout

\begin_layout Standard
• In many systems, the cost associated with each migration — i.e.
 , the cost of transferring a job’s context from one processor to another
 — can be prohibitive.
 
\end_layout

\begin_layout Standard
• Until recently, traditional real-time scheduling theory lacked the techniques,
 tools, and results to permit a detailed analysis of systems that allow
 migration.
 Hence, partitioning has been the preferred approach due largely to the
 non-existence of viable alternative approaches.
 Recent developments in computer architecture, including single-chip multiproces
sors and very fast interconnection networks over small areas, have resulted
 in the first of these concerns becoming less of an issue.
 Thus, system designers need no longer rule out interprocessor migration
 solely due to implementation considerations, especially in tightly-coupled
 systems.
 (However, it may still be desirable to strict overhead in order to reduce
 runtime overhead.) In addition, results of recent experiments demonstrate
 that scheduling algorithms that allow migration are competitive in terms
 of schedulability with those that do not migrate, even after incorporating
 migration overheads [26].
 This is due to the fact that systems exist that can be successfully scheduled
 only if interprocessor 5 migration is allowed (refer to Lemmas 3 and 4
 in Section 3)
\end_layout

\begin_layout Standard
Migration addresses points 5 and 6 of the protocol : A thread that is spinning
 for a lock already held on another processor must be able to give way to
 the preempted holder locally.
\end_layout

\begin_layout Subsection
Schedulability Analysis
\end_layout

\begin_layout Subsection
Runtime Overhead in SMP computers
\end_layout

\begin_layout Subsection
Limitations
\end_layout

\begin_layout Subsection
Project Goals Revisited and Project Requirements
\end_layout

\begin_layout Section
MrsP : Design and Implementation
\end_layout

\begin_layout Subsection
Linux real-time scheduling algorithm
\end_layout

\begin_layout Subsubsection
Kernel Preemption
\end_layout

\begin_layout Itemize
Linux, prior to the 2.5 Linux Kernel, was a non-preemptive kernel.
 That means that whenever a thread was running in 
\series bold
kernel context
\series default
 (for instance a user application making a system call) that thread would
 not be preempted unless it volunteered to schedule (calls yield() function)
 -> basic Non Preemptive Protocol.
 The 2.6 version of the Linux Kernel introduces preemption and protects critical
 section through the use of spin-locks e.g.
 busy-waiting locks 
\begin_inset CommandInset citation
LatexCommand cite
key "rostedt2007internals"

\end_inset

.
 This was a major improvement however it still allowed lower threads blocking
 higher threads requesting access to the same shared resource or not.
 It makes sense for a spinlock to be fully non-preemptible for the following
 reasons: 
\end_layout

\begin_layout Itemize
Busy-waiting blocks a whole processor, we want to access and leave the critical
 section rapidly.
 
\end_layout

\begin_layout Itemize
Other tasks might be spinning on different processors for the same lock
\end_layout

\begin_layout Itemize
Interrupt kernel threads [
\series bold
Define
\series default
] are given priority over all other tasks, they can spin on the lock held
 by the preempted task and thus create a deadlock.
\end_layout

\begin_layout Standard
However spinlocks can create large non-deterministic latencies and that
 is conflicting with the requirements of an RTOS.
\end_layout

\begin_layout Standard
To address that issue the RT patch converts most spinlocks into a mutex
 
\begin_inset CommandInset citation
LatexCommand cite
key "rostedt2007internals"

\end_inset

, this has the effect to enable preemption in the critical sections as a
 task trying to lock an already held mutex will be suspended (deadlock avoided).
\end_layout

\begin_layout Subsubsection
Priority Inheritance Implementation
\end_layout

\begin_layout Standard
Priority inversion, e.g.
 lower tasks blocking higher ones is inherent to scheduling and can not
 be avoided, however unbounded priority inversion must be prevented.
 The RT patch chooses priority inheritance to address this issue.
\end_layout

\begin_layout Standard
The implementation of a PI mutex introduces a new concept, the priority
 inheritance chain described in 
\begin_inset CommandInset citation
LatexCommand cite
key "rostedt_rt_mutex"

\end_inset

.
\end_layout

\begin_layout Standard
The PI chain is an ordered series of locks and processes that cause tasks
 to inherit priorities from a higher process that is blocked on one of its
 locks.
 Different chains may be merged as several tasks can wait on a lock, but
 a chain would never diverge, since a task can't be blocked on more than
 one lock at a time.
 
\end_layout

\begin_layout Subsubsection
High Resolution Timers
\end_layout

\begin_layout Subsubsection
Comparison with other RTOSes
\end_layout

\begin_layout Subsubsection
Implementation in Linux Kernel
\end_layout

\begin_layout Subsubsection
The Linux real-time scheduling algorithm
\end_layout

\begin_layout Subsubsection
Key Data Structures
\end_layout

\begin_layout Paragraph
task_struct
\end_layout

\begin_layout Standard
This data structure represents a task in the system.
 It contains useful information for the scheduler such as the real-time
 priority of a task, its current state (running, sleeping, etc..) and the
 policy under which it is being scheduled.
 
\end_layout

\begin_layout Paragraph
runqueue
\end_layout

\begin_layout Standard
There is two runqueue per processor, one of which is listing the active
 tasks and the other the expired tasks.
 A runqueue is a linked list composed of 140 nodes corresponding to each
 priority level.
 Each node is itself a linked list referencing the tasks of the same priority.
\end_layout

\begin_layout Paragraph
futex
\end_layout

\begin_layout Standard
A futex, 
\begin_inset Quotes eld
\end_inset

Fast userspace mutex
\begin_inset Quotes erd
\end_inset

, is a locking primitive that is used to build more complex locking structures.
 It is composed of a 32 bits integer and a waitqueue referencing the tasks
 waiting to acquire the lock.
 It is used in mutexes when there is contention over a lock (a task is waiting
 for a lock already hold).
\end_layout

\begin_layout Paragraph
rt_mutex
\end_layout

\begin_layout Standard
Also called Priority inheritance futex, like with futexes, the waiting task
 is added to a waitqueue.
 If its priority is higher than the holder's, it rises the holder's priority
 to its own priority.
 The priority inheritance is dynamic in the sense that, if the holder is
 itself waiting on a second futex, its temporarily enhanced priority will
 diffuse to the holder of the second futex.
 As soon as a task unlocks a futex its enhanced priority is set back to
 its initial one.
\end_layout

\begin_layout Subsubsection
Real-time scheduler
\end_layout

\begin_layout Standard
root domains
\end_layout

\begin_layout Standard
Pull and Push algorithms
\end_layout

\begin_layout Standard
[INCLUDE CHART]
\end_layout

\begin_layout Subsubsection
Priority Management in kernel
\end_layout

\begin_layout Subsection
Requirements of MrsP
\end_layout

\begin_layout Enumerate
Be able to assign one priority per processor to spinlocks
\end_layout

\begin_layout Enumerate
Make waiters spin and be able to get preempted only by holder
\end_layout

\begin_layout Enumerate
Make waiters add their affinities to holder
\end_layout

\begin_layout Enumerate
FIFO Spinlock
\end_layout

\begin_layout Subsection
FIFO Spinlock
\end_layout

\begin_layout Standard
In multithreading, spinlocks are rarely used, most applications favor the
 more sophisticated solution of mutexes.
 However with sophistication comes complexity, and complexity in computing
 often means slower response times.
 At kernel level, performance is crucial and areas are often protected with
 very short busy-waiting locks.
 Typically the spinlock is implemented as single variable acting as boolean
 indicating whether the resource is currently being used, tasks enter a
 loop and check continuously its value.
 MrsP requires busy-waiting, but not only, it also requires that a FIFO
 access to the lock is respected.
 The Pthread implementation for instance doesn't provide such a facility,
 resulting in threads competing for the lock.
 The three others requirements for MrsP are affinity inheritance, priority
 ceiling and the ability to assign one priority per processor to each lock.
 The following sections will give the details of a custom FIFO spinlock
 implemented to fulfill the above requirements.
\end_layout

\begin_layout Subsubsection
FIFO Spinlock basic algorithm
\end_layout

\begin_layout Standard
Our implementation is inspired from 
\begin_inset Quotes eld
\end_inset

Tickets Spinlocks
\begin_inset Quotes erd
\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "Piggin_ticket_spin"

\end_inset

 and the Lamport Bakery Algorithm.
 Below 
\series bold
[EXPLAIN]
\series default
 is a pseudo-code describing the algorithm.
\end_layout

\begin_layout Standard
\begin_inset listings
lstparams "basicstyle={\ttfamily},language=C"
inline false
status open

\begin_layout Plain Layout

LOCK {
\end_layout

\begin_layout Plain Layout

owner;
\end_layout

\begin_layout Plain Layout

next_ticket;
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

FIFO_Spin_Lock(LOCK L){
\end_layout

\begin_layout Plain Layout

 Atomic{
\end_layout

\begin_layout Plain Layout

 Local Ticket = L.next_ticket;
\end_layout

\begin_layout Plain Layout

 increment L.next_ticket;
\end_layout

\begin_layout Plain Layout

 }
\end_layout

\begin_layout Plain Layout

 WHILE Ticket != L.owner
\end_layout

\begin_layout Plain Layout

	Spin
\end_layout

\begin_layout Plain Layout

 ENDWHILE
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

FIFO_Spin_Unlock(LOCK L){
\end_layout

\begin_layout Plain Layout

 increment L.owner
\end_layout

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
The lock variables are initialized to zero at the beginning.
 The task calling FIFO_Spin_Lock starts by atomically getting a ticket number
 and increasing it by one.
 The task then spins in a busy loop waiting for its ticket number to be
 equal to the owner variable.
 The unlocking is done by a simple (atomic?) increase of the owner variable.
 
\end_layout

\begin_layout Standard
The 
\family typewriter
owner
\family default
 and 
\family typewriter
next_ticket
\family default
 are defined as unsigned 1 byte variables in our implementation which means
 there can be up to 255 tasks spinning on the same lock.
 We can notice that code above always increments the variable and never
 decrease them, which can lead to ask 
\begin_inset Quotes eld
\end_inset

How many accesses/tickets can a 1 byte variable provide
\begin_inset Quotes erd
\end_inset

.
 The algorithm takes advantage of the 
\family typewriter
\shape italic
wrapping
\family default
\shape default
 property of unsigned variables which resets the variable to zero in the
 case of an overflow.
 FIFO spinlocks therefore support an infinite number of accesses.
 
\end_layout

\begin_layout Subsubsection
FIFO Spinlock structure
\end_layout

\begin_layout Standard
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

struct fifo_spinlock_chart { 
\end_layout

\begin_layout Plain Layout

volatile pid_t  taskid; 
\end_layout

\begin_layout Plain Layout

volatile unsigned char owner; 
\end_layout

\begin_layout Plain Layout

volatile unsigned char next; 
\end_layout

\begin_layout Plain Layout

volatile unsigned char prio; 
\end_layout

\begin_layout Plain Layout

volatile unsigned char task_prio; 
\end_layout

\begin_layout Plain Layout

cpu_set_t saved_cpumask;
\end_layout

\begin_layout Plain Layout

} ;
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
taskid : This variable stores the task id of the task currently holding
 the lock (defaults to -1).
\end_layout

\begin_layout Itemize
owner : This variable keeps track of the ticket owner.
\end_layout

\begin_layout Itemize
next : This variable keeps track of the waiters to allow a FIFO access.
\end_layout

\begin_layout Itemize
prio : This variable is the priority ceiling of the lock.
\end_layout

\begin_layout Itemize
task_prio : This variable saves the priority the task had before attempting
 to take the lock.
\end_layout

\begin_layout Itemize
saved_cpumask : This variable saves the cpu affinities the task had before
 attempting to take the lock.
\end_layout

\begin_layout Paragraph
Priority ceiling
\end_layout

\begin_layout Standard
While POSIX Pthread mutexes specify and implement priority ceiling, Pthread
 spinlocks are kept very simple and do not benefit of such feature, because
 their rationale is performance and their use cases make them a rarely used
 feature of multithreading.
\end_layout

\begin_layout Paragraph
Affinity inheritance
\end_layout

\begin_layout Standard
MrsP requires waiting tasks to add the current cpu they are spinning on
 to the list of cpu affinities of the holder in case it gets preempted.
 This can be defined as 
\shape italic
affinity inheritance
\shape default
.
 The mechanism is very similar to the mechanism priority inheritance uses.
 When a task is waiting on a contended spinlock, it adds the cpu it is currently
 executing on to the holding task.
 This way in case of a forced migration e.g due to preemption, the holder
 task can migrate to processor where the task is currently waiting on the
 spinlock and preempt it.
 
\end_layout

\begin_layout Paragraph
Priority per processor
\end_layout

\begin_layout Standard
MrsP requires to have one priority per processor in case a task is preempted
 and migrated to another cpu.
 This is further described in TODO
\end_layout

\begin_layout Subsubsection
FIFO Spinlock MrsP Algorithm
\end_layout

\begin_layout Standard

\family typewriter
\begin_inset listings
lstparams "basicstyle={\normalsize\ttfamily},language=C"
inline false
status open

\begin_layout Plain Layout

LOCK {
\end_layout

\begin_layout Plain Layout

  owner;
\end_layout

\begin_layout Plain Layout

  next_ticket;
\end_layout

\begin_layout Plain Layout

  taskid;
\end_layout

\begin_layout Plain Layout

  prio_per_cpu;
\end_layout

\begin_layout Plain Layout

  save_task_prio;
\end_layout

\begin_layout Plain Layout

  save_task_affinity;
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

FIFO_Spin_Lock(LOCK L){
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

 #Declare local variables
\end_layout

\begin_layout Plain Layout

 Local copy_priority, copy_affinity
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

 copy_priority = Current Task.Priority
\end_layout

\begin_layout Plain Layout

 copy_affinity = Current Task.Affinity
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

 #Priority ceiling
\end_layout

\begin_layout Plain Layout

 Task.Prio_Per_CPU = L.prio_per_cpu
\end_layout

\begin_layout Plain Layout

 
\end_layout

\begin_layout Plain Layout

 Atomic{
\end_layout

\begin_layout Plain Layout

 Local Ticket = L.next_ticket;
\end_layout

\begin_layout Plain Layout

 increment L.next_ticket;
\end_layout

\begin_layout Plain Layout

 }
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

 #Affinity Inheritance to holder
\end_layout

\begin_layout Plain Layout

 IF L.taskid != NULL
\end_layout

\begin_layout Plain Layout

    ADD_Current_CPU(Task(L.taskid));
\end_layout

\begin_layout Plain Layout

 ENDIF
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

 WHILE Ticket != L.owner
\end_layout

\begin_layout Plain Layout

	Spin
\end_layout

\begin_layout Plain Layout

 ENDWHILE
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

 L.taskid = Current Task.ID
\end_layout

\begin_layout Plain Layout

 L.save_affinity = copy_affinity;
\end_layout

\begin_layout Plain Layout

 L.save_priority = copy_priority;
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

FIFO_Spin_Unlock(LOCK L){
\end_layout

\begin_layout Plain Layout

 L.taskid = undef
\end_layout

\begin_layout Plain Layout

 Task.Affinities = L.save_affinity
\end_layout

\begin_layout Plain Layout

 Task.Prio = L.save_priority
\end_layout

\begin_layout Plain Layout

 increment L.owner
\end_layout

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Implementation of MrsP 
\end_layout

\begin_layout Subsubsection
System calls
\end_layout

\begin_layout Standard
A system call (also called kernel call) is a request to a service typically
 made from userspace.
 The service needed is usually only accessible by the kernel because of
 its possible misuse that could damage the system integrity.
 System calls act as an Application Programming Interface for the kernel
 functions and enable to abstract hardware in a safe fashion from the user.
 As stated in the book Linux Kernel Development 
\begin_inset CommandInset citation
LatexCommand cite
key "love2010linux"

\end_inset

 : 
\shape italic
if tasks were free to access system and hardware resources without the kernel's
 knowledge, it would be nearly impossible to implement multitasking and
 virtual memory, and certainly impossible to do so with stability and security.
\end_layout

\begin_layout Paragraph
System call handler
\end_layout

\begin_layout Paragraph
System call overhead
\end_layout

\begin_layout Subsubsection
Modifications to the Linux Kernel
\end_layout

\begin_layout Standard
We have added a variable in the task_struct definition that can hold one
 priority per processor.
\end_layout

\begin_layout Standard
We have added a bitmask in the task_struct definition that holds the inherited
 processor affinities.
 Those are added to the task holding the lock and removed when it releases
 the lock.
\end_layout

\begin_layout Standard
We have added a boolean variable to make a task scheduled under our algorithm.
 TODO to be modified for a new scheduling policy (SCHED_MRSP).
\end_layout

\begin_layout Standard
A call to sys_futex with SCHED_MRSP makes the thread spin at local ceiling
 for the rt-mutex.
\end_layout

\begin_layout Standard
The task is checked when being migrated between two cpus, if a task is spinning
 on that cpu, it raises its own priority to task_on_other_cpu +1 so that
 it can preempt it.
\end_layout

\begin_layout Standard
We take advantage of the previously implemented PI-futexes.
\end_layout

\begin_layout Paragraph
Task migration
\end_layout

\begin_layout Standard
When the task is being migrated by the scheduler, we detect it and modify
 it before it gets added to the target cpu.
\end_layout

\begin_layout Subsubsection
MRSP API
\end_layout

\begin_layout Standard
A system call sys_set_smp_prio allows to set one priority per task.
\end_layout

\begin_layout Standard
Task spinning giving up its share -> cooperative scheduling ?
\end_layout

\begin_layout Subsection
Semi-partitioned systems considerations
\end_layout

\begin_layout Subsection
Globally partitioned systems considerations
\end_layout

\begin_layout Subsection
Limitations
\end_layout

\begin_layout Section
Results and evaluation
\end_layout

\begin_layout Subsection
Tools
\end_layout

\begin_layout Subsubsection
QEMU
\end_layout

\begin_layout Subsubsection
Kernelshark and trace-cmd
\end_layout

\begin_layout Subsubsection
ftrace & profiling
\end_layout

\begin_layout Subsection
Hardware
\end_layout

\begin_layout Subsection
Test Cases
\end_layout

\begin_layout Section
Conclusion and Further Work
\end_layout

\begin_layout Subsection
Project Review
\end_layout

\begin_layout Subsection
Overview of the project
\end_layout

\begin_layout Subsection
Strengths
\end_layout

\begin_layout Subsection
Weaknesses
\end_layout

\begin_layout Subsection
Limitations
\end_layout

\begin_layout Subsection
Recommendation for further research
\end_layout

\begin_layout Standard
Given the plethora of available resource sharing protocols.
\end_layout

\begin_layout Standard
Each resource sharing protocol seems to suit a particular type of programming
 (slow or quick resources, intensive or sparse sharing, number of tasks,
 etc..).
 An approach that might be considered is to build a framework that automatically
 selects the best resource sharing algorithm for a given program.
 Why not even think about dynamically changing a policy during runtime,
 going to the realm of strategy (schedulability) and tactics (different
 protocols).
\end_layout

\begin_layout Subsection
Final Words
\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "cite"
options "plain"

\end_inset


\end_layout

\end_body
\end_document
